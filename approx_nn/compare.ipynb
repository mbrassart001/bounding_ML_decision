{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict \n",
    "from sklearn import metrics, model_selection\n",
    "from torch.autograd import Function\n",
    "from torch.optim import Adam\n",
    "\n",
    "filepath = os.path.abspath('')\n",
    "sys.path.append(os.path.join(filepath, \"..\", \"compiling_nn\"))\n",
    "sys.path.append(os.path.join(filepath, \"..\", \"datasets\", \"loan\"))\n",
    "from build_odd import compile_nn\n",
    "from loan import get_loan_dataset\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([280, 14])\n"
     ]
    }
   ],
   "source": [
    "np_x, np_y = get_loan_dataset(balancing=True, discretizing=False, hot_encoding=True, rmv_pct=0.985)\n",
    "x_data, y_data = torch.Tensor(np_x), torch.Tensor(np_y)\n",
    "input_size = x_data.size(1)\n",
    "print(x_data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics, Activations, Loss and Networks definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(y_true, y_pred):\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix, display_labels=[False, True])\n",
    "    return cm_display\n",
    "\n",
    "def plot_cm(y_true, y_pred):\n",
    "    cm_display = cm(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4,8))\n",
    "    cm_display.plot(ax=ax, colorbar=False)\n",
    "\n",
    "def plot_combine_cm(cms, titles=None):\n",
    "    n = len(cms)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(4*n, 8))\n",
    "    if titles:\n",
    "        for ax, cm, title in zip(axs, cms, titles):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "            ax.set_title(title)\n",
    "    else:\n",
    "        for ax, cm in zip(axs, cms):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "    fig.tight_layout()\n",
    "\n",
    "def cov_score(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    scores = {}\n",
    "\n",
    "    for label in labels:\n",
    "        indices_true = np.where(y_true == label)[0]\n",
    "        indices_pred = np.where(y_pred == label)[0]\n",
    "        scores[label] = len(np.intersect1d(indices_true, indices_pred))/len(indices_true)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def cross_valid(X, Y, train_func, skf, **kw_train):\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        model, y_pred = train_func(x_train, y_train, **kw_train)\n",
    "        model.eval()\n",
    "        yield y_pred.detach().round(), y_train, model(x_test).detach(), y_test\n",
    "\n",
    "def tnot(a): return torch.logical_not(a)\n",
    "def tor(a,b): return torch.logical_or(a,b)\n",
    "def tand(a,b): return torch.logical_and(a,b)\n",
    "def txor(a,b): return torch.logical_xor(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = torch.where(input>=0, torch.tensor(1.0), torch.tensor(0.0))\n",
    "        ctx.save_for_backward(input)\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = torch.zeros_like(input)\n",
    "        return grad_input\n",
    "    \n",
    "class StepActivation(nn.Module):\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            return torch.sigmoid(input)\n",
    "        else:\n",
    "            return StepFunction.apply(input)\n",
    "    \n",
    "class AsymMSELoss(nn.Module): # https://www.desmos.com/calculator/zmxcluqhkt\n",
    "    def __init__(self, p=2):\n",
    "        super(AsymMSELoss, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        dif = label - input\n",
    "        a = torch.square(dif)\n",
    "        b = a*self.p\n",
    "        loss = torch.where(dif < 0, b, a)\n",
    "        loss = torch.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "class AsymBCELoss(nn.Module):\n",
    "    def __init__(self, p=2):\n",
    "        super(AsymBCELoss, self).__init__()\n",
    "        assert(p>0)\n",
    "        self.p1 = p if p >= 1 else 1\n",
    "        self.p2 = 1/p if p < 1 else 1\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        loss1 = torch.log(1-input+1e-8)\n",
    "        loss1 = loss1.clamp(min=-100)\n",
    "        loss2 = torch.log(input+1e-8)\n",
    "        loss2 = loss2.clamp(min=-100)\n",
    "        loss = -(self.p1*(1-label)*loss1+self.p2*label*loss2)\n",
    "        \n",
    "        loss = torch.mean(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproxNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        hl1 = 10\n",
    "\n",
    "        self.nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', StepActivation()),\n",
    "            ('l2', nn.Linear(hl1,1)),\n",
    "            ('a2', StepActivation())\n",
    "        ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CentralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self. nn = nn.Sequential(\n",
    "            nn.Linear(input_size,hl1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl1,hl2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl2,1),\n",
    "            StepActivation(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class BoundNetResults():\n",
    "    def __init__(self, x, xhi, xnn, xlo):\n",
    "        self.x = x\n",
    "        self.hi = xhi\n",
    "        self.nn = xnn\n",
    "        self.lo = xlo\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if hasattr(self.x, name):\n",
    "            return getattr(self.x, name)\n",
    "        else:\n",
    "            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
    "    \n",
    "    def __dir__(self):\n",
    "        return dir(self.x)\n",
    "    \n",
    "    def detach(self):\n",
    "        self.x = self.x.detach()\n",
    "        self.hi = self.hi.detach()\n",
    "        self.nn = self.nn.detach()\n",
    "        self.lo = self.lo.detach()\n",
    "        return self\n",
    "    \n",
    "    def round(self, *args):\n",
    "        self.x = self.x.round(*args)\n",
    "        self.hi = self.hi.round(*args)\n",
    "        self.nn = self.nn.round(*args)\n",
    "        self.lo = self.lo.round(*args)\n",
    "        return self\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join([str(t) for t in (self.x, self.hi, self.nn, self.lo)])\n",
    "\n",
    "class BoundNetLoss():\n",
    "    def __init__(self, hi, nn, lo):\n",
    "        self.hi_loss_fn = hi\n",
    "        self.nn_loss_fn = nn\n",
    "        self.lo_loss_fn = lo\n",
    "\n",
    "    def __call__(self, pred, true):\n",
    "        self.nn_loss = self.nn_loss_fn(pred.nn, true)\n",
    "\n",
    "        target = pred.nn.detach()\n",
    "        self.hi_loss = self.hi_loss_fn(pred.hi, target)\n",
    "        self.lo_loss = self.lo_loss_fn(pred.lo, target)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def backward(self):\n",
    "        self.nn_loss.backward()\n",
    "        self.hi_loss.backward()\n",
    "        self.lo_loss.backward()\n",
    "\n",
    "class BoundNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # high approx nn (bigger = very long to compute into ODD)\n",
    "        self.hi = ApproxNet()\n",
    "\n",
    "        # low approx nn\n",
    "        self.lo = ApproxNet()\n",
    "\n",
    "        # nn to approximate (can make it bigger easily)\n",
    "        self.nn = CentralNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        xhi = self.hi(x)\n",
    "        xnn = self.nn(x)\n",
    "        xlo = self.lo(x)\n",
    "        x = torch.where(xhi>0.5, xhi, torch.where(xlo<0.5, xlo, xnn))\n",
    "        \n",
    "        x = BoundNetResults(x, xhi, xnn, xlo)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Linear(input_size,hl1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl1,hl2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl2,1),\n",
    "            StepActivation(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, model, loss_fn, optimizer, max_epoch):\n",
    "    for _ in range(max_epoch):\n",
    "        model.train()\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, y_pred\n",
    "\n",
    "def train_boundnet(x, y, max_epoch=5000, learning_rate=1e-2, weight_decay=1e-6):\n",
    "    model = BoundNet()\n",
    "    loss_fn = BoundNetLoss(AsymBCELoss(50), nn.BCELoss(), AsymBCELoss(.02))\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    return train_model(x, y, model, loss_fn, optimizer, max_epoch=max_epoch)\n",
    "\n",
    "def train_simplenet(x, y, max_epoch=5000, learning_rate=1e-2, weight_decay=1e-6):\n",
    "    model = SimpleNet()\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    return train_model(x, y, model, loss_fn, optimizer, max_epoch=max_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def show_activation(act, output):\n",
    "    # Mean activation per output\n",
    "    act_ones  = torch.where(output==1, act, torch.zeros(act.size()))\n",
    "    act_zeros = torch.where(output==0, act, torch.zeros(act.size()))\n",
    "\n",
    "    mean_ones  = torch.mean(act_ones, dim=0)\n",
    "    mean_zeros = torch.mean(act_zeros, dim=0)\n",
    "\n",
    "    # Figure initialization\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    tick_kw = {'left': False, 'bottom': False, 'labelleft': False}\n",
    "\n",
    "    # Normalize cmap accross both images\n",
    "    min_act = min(mean_ones.min().item(), mean_zeros.min().item())\n",
    "    max_act = max(mean_ones.max().item(), mean_zeros.max().item())\n",
    "\n",
    "    color_map = 'PRGn'\n",
    "\n",
    "    ax[0].imshow(mean_zeros.unsqueeze(0), cmap=color_map, vmin=min_act, vmax=max_act)\n",
    "    ax[0].tick_params(**tick_kw)\n",
    "    ax[0].set_title(\"activation moyenne de la couche cachée avec 0 en sortie\")\n",
    "\n",
    "    ax[1].imshow(mean_ones.unsqueeze(0), cmap=color_map, vmin=min_act, vmax=max_act)\n",
    "    ax[1].tick_params(**tick_kw)\n",
    "    ax[1].set_title(\"activation moyenne de la couche cachée avec 1 en sortie\")\n",
    "\n",
    "    # Show text on cells\n",
    "    for i, (v0, v1) in enumerate(zip(mean_zeros, mean_ones)):\n",
    "        ax[0].text(i, 0, f\"{v0.item():.2f}\", ha=\"center\", va=\"center\")\n",
    "        ax[1].text(i, 0, f\"{v1.item():.2f}\", ha=\"center\", va=\"center\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_activation(net, layer, data):\n",
    "    net.eval()\n",
    "    getattr(net, layer).register_forward_hook(get_activation('__net__'))\n",
    "    output = net(data).detach()\n",
    "    act = activation.pop('__net__').squeeze()\n",
    "    show_activation(act, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold   1 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.813    |    SimpleNet      0.800    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.769    |    Low            0.765    ||    High           0.817    |    Low            0.851\n",
      "\tCoverage      High           0.714    |    Low            0.929    ||    High           0.690    |    Low            1.000\n",
      "\t              High           0.857    |    Low            0.500    ||    High           1.000    |    Low            0.651\n",
      "Fold   2 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.733    |    SimpleNet      0.733    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.583    |    Low            0.824    ||    High           0.794    |    Low            0.837\n",
      "\tCoverage      High           0.500    |    Low            1.000    ||    High           0.659    |    Low            1.000\n",
      "\t              High           0.786    |    Low            0.571    ||    High           1.000    |    Low            0.611\n",
      "Fold   3 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.759    |    SimpleNet      0.759    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.545    |    Low            0.727    ||    High           0.794    |    Low            0.863\n",
      "\tCoverage      High           0.429    |    Low            0.857    ||    High           0.659    |    Low            1.000\n",
      "\t              High           0.857    |    Low            0.500    ||    High           1.000    |    Low            0.683\n",
      "Fold   4 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.765    |    SimpleNet      0.750    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.857    |    Low            0.778    ||    High           0.885    |    Low            0.840\n",
      "\tCoverage      High           0.857    |    Low            1.000    ||    High           0.794    |    Low            1.000\n",
      "\t              High           0.857    |    Low            0.429    ||    High           1.000    |    Low            0.619\n",
      "Fold   5 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.640    |    SimpleNet      0.640    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.455    |    Low            0.765    ||    High           0.714    |    Low            0.818\n",
      "\tCoverage      High           0.357    |    Low            0.929    ||    High           0.556    |    Low            1.000\n",
      "\t              High           0.786    |    Low            0.500    ||    High           1.000    |    Low            0.556\n",
      "Fold   6 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.545    |    SimpleNet      0.786    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.235    |    Low            0.593    ||    High           0.759    |    Low            0.887\n",
      "\tCoverage      High           0.143    |    Low            0.571    ||    High           0.611    |    Low            1.000\n",
      "\t              High           0.929    |    Low            0.643    ||    High           1.000    |    Low            0.746\n",
      "Fold   7 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.733    |    SimpleNet      0.759    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.522    |    Low            0.688    ||    High           0.694    |    Low            0.881\n",
      "\tCoverage      High           0.429    |    Low            0.786    ||    High           0.532    |    Low            1.000\n",
      "\t              High           0.786    |    Low            0.500    ||    High           1.000    |    Low            0.730\n",
      "Fold   8 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.741    |    SimpleNet      0.786    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.583    |    Low            0.788    ||    High           0.833    |    Low            0.863\n",
      "\tCoverage      High           0.500    |    Low            0.929    ||    High           0.714    |    Low            1.000\n",
      "\t              High           0.786    |    Low            0.571    ||    High           1.000    |    Low            0.683\n",
      "Fold   9 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.600    |    SimpleNet      0.600    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.400    |    Low            0.684    ||    High           0.777    |    Low            0.846\n",
      "\tCoverage      High           0.286    |    Low            0.929    ||    High           0.635    |    Low            1.000\n",
      "\t              High           0.857    |    Low            0.214    ||    High           1.000    |    Low            0.635\n",
      "Fold  10 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.710    |    SimpleNet      0.667    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.692    |    Low            0.778    ||    High           0.844    |    Low            0.834\n",
      "\tCoverage      High           0.643    |    Low            1.000    ||    High           0.730    |    Low            1.000\n",
      "\t              High           0.786    |    Low            0.429    ||    High           1.000    |    Low            0.603\n"
     ]
    }
   ],
   "source": [
    "skf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=104)\n",
    "bnet_split_res = cross_valid(x_data, y_data, train_boundnet, skf)\n",
    "snet_split_res = cross_valid(x_data, y_data, train_simplenet, skf)\n",
    "\n",
    "dict_metrics = {(modelname, metric, key): [] for modelname in (\"boundnet\", \"simplenet\", \"hinet\", \"lonet\") \n",
    "                for metric in (\"f1score\", \"coverage0\", \"coverage1\") for key in (\"valid\", \"train\")}\n",
    "\n",
    "for i, ((bt, tt, bv, tv), (st, _, sv, _)) in enumerate(zip(bnet_split_res, snet_split_res)):\n",
    "    prompts = []\n",
    "    sep_model = f\"{'|':^9}\"\n",
    "    for k, b, s, t in [[\"valid\", bv, sv, tv], [\"train\", bt, st, tt]]:\n",
    "        b_f1_score = metrics.f1_score(t, b, average=\"binary\")\n",
    "        s_f1_score = metrics.f1_score(t, s, average=\"binary\")\n",
    "        prompts.append(f\"{'BoundNet':<15}{b_f1_score:.3f}{sep_model}{'SimpleNet':<15}{s_f1_score:.3f}\")\n",
    "        dict_metrics[('boundnet', 'f1score', k)].append(b_f1_score)\n",
    "        dict_metrics[('simplenet', 'f1score', k)].append(s_f1_score)\n",
    "\n",
    "        hi_f1_score = metrics.f1_score(t, b.hi, average=\"binary\")\n",
    "        lo_f1_score = metrics.f1_score(t, b.lo, average=\"binary\")\n",
    "        prompts.append(f\"{'High':<15}{hi_f1_score:.3f}{sep_model}{'Low':<15}{lo_f1_score:.3f}\")\n",
    "        dict_metrics[('hinet', 'f1score', k)].append(hi_f1_score)\n",
    "        dict_metrics[('lonet', 'f1score', k)].append(lo_f1_score)\n",
    "\n",
    "        hi_cov_score = cov_score(t, b.hi)\n",
    "        lo_cov_score = cov_score(t, b.lo)\n",
    "        prompts.append(f\"{'High':<15}{hi_cov_score[1]:.3f}{sep_model}{'Low':<15}{lo_cov_score[1]:.3f}\")\n",
    "        prompts.append(f\"{'High':<15}{hi_cov_score[0]:.3f}{sep_model}{'Low':<15}{lo_cov_score[0]:.3f}\")\n",
    "        dict_metrics[('hinet', 'coverage1', k)].append(hi_cov_score[1])\n",
    "        dict_metrics[('lonet', 'coverage1', k)].append(lo_cov_score[1])\n",
    "        dict_metrics[('hinet', 'coverage0', k)].append(hi_cov_score[0])\n",
    "        dict_metrics[('lonet', 'coverage0', k)].append(lo_cov_score[0])\n",
    "\n",
    "    sep_tv = f\"{'||':^10}\"\n",
    "    print(f\"Fold {i+1:3} :            {'Valid':^49}{sep_tv}{'Train':^49}\",\n",
    "          f\"\\tF1 score      {prompts[0]}{sep_tv}{prompts[4]}\",\n",
    "          f\"\\t              {prompts[1]}{sep_tv}{prompts[5]}\",\n",
    "          f\"\\tCoverage      {prompts[2]}{sep_tv}{prompts[6]}\",\n",
    "          f\"\\t              {prompts[3]}{sep_tv}{prompts[7]}\",\n",
    "          sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average  :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.704    |    SimpleNet      0.728    ||    BoundNet       1.000    |    SimpleNet      1.000\n",
      "\t              High           0.564    |    Low            0.739    ||    High           0.791    |    Low            0.852\n",
      "\tCoverage      High           0.486    |    Low            0.893    ||    High           0.658    |    Low            1.000\n",
      "\t              High           0.829    |    Low            0.486    ||    High           1.000    |    Low            0.652\n"
     ]
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame.from_dict(dict_metrics, orient='index')\n",
    "mean_metrics = df_metrics.mean(axis=1)\n",
    "mean_prompts = [\n",
    "    f\"{'BoundNet':<15}{mean_metrics[('boundnet', 'f1score', 'valid')]:.3f}{sep_model}{'SimpleNet':<15}{mean_metrics[('simplenet', 'f1score', 'valid')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'f1score', 'valid')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'f1score', 'valid')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'coverage1', 'valid')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'coverage1', 'valid')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'coverage0', 'valid')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'coverage0', 'valid')]:.3f}\",\n",
    "    f\"{'BoundNet':<15}{mean_metrics[('boundnet', 'f1score', 'train')]:.3f}{sep_model}{'SimpleNet':<15}{mean_metrics[('simplenet', 'f1score', 'train')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'f1score', 'train')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'f1score', 'train')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'coverage1', 'train')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'coverage1', 'train')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'coverage0', 'train')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'coverage0', 'train')]:.3f}\",\n",
    "]\n",
    "print(f\"Average  :            {'Valid':^49}{sep_tv}{'Train':^49}\",\n",
    "          f\"\\tF1 score      {mean_prompts[0]}{sep_tv}{mean_prompts[4]}\",\n",
    "          f\"\\t              {mean_prompts[1]}{sep_tv}{mean_prompts[5]}\",\n",
    "          f\"\\tCoverage      {mean_prompts[2]}{sep_tv}{mean_prompts[6]}\",\n",
    "          f\"\\t              {mean_prompts[3]}{sep_tv}{mean_prompts[7]}\",\n",
    "          sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
