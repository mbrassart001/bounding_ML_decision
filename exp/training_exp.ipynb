{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam\n",
    "from sklearn import metrics\n",
    "from collections import OrderedDict \n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import datasets\n",
    "import utils.more_torch_functions as mtf\n",
    "from utils.modules import Parallel, MaxLayer\n",
    "from utils.custom_activations import StepActivation\n",
    "from utils.custom_loss import AsymBCELoss\n",
    "from utils.misc import train_model\n",
    "\n",
    "seed = 2872\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "SAVE_PATH = os.path.join(os.path.abspath('..'), \"backup\")\n",
    "PKL_PATH = os.path.join(SAVE_PATH, \"bdd\")\n",
    "PTH_PATH = os.path.join(SAVE_PATH, \"nn\")\n",
    "METRIC_PATH = os.path.join(SAVE_PATH, \"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 29])\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.DiabetesDataset\n",
    "\n",
    "np_x, np_y = dataset.get_dataset(balancing=True, discretizing=True, hot_encoding=True)\n",
    "x_data, y_data = torch.Tensor(np_x), torch.Tensor(np_y)\n",
    "input_size = x_data.size(1)\n",
    "print(x_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(x_train, y_train, x_valid, y_valid, model, metrics_average=\"binary\"):\n",
    "    model.eval()\n",
    "    pred_train = model(x_train).detach()\n",
    "    pred_valid = model(x_valid).detach()\n",
    "\n",
    "    p_train, r_train, f_train, _ = metrics.precision_recall_fscore_support(y_train, pred_train, beta=1, average=metrics_average, labels=[0,1])\n",
    "    p_valid, r_valid, f_valid, _ = metrics.precision_recall_fscore_support(y_valid, pred_valid, beta=1, average=metrics_average, labels=[0,1])\n",
    "\n",
    "    return f_train, p_train, r_train, f_valid, p_valid, r_valid\n",
    "\n",
    "def train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer, epochs=50, metrics_average=\"binary\"):\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "    return eval_model(x_train, y_train, x_valid, y_valid, model, metrics_average)\n",
    "\n",
    "def print_eval(x_train, y_train, x_valid, y_valid, model, criterion, optimizer):\n",
    "    f_train, p_train, r_train, f_valid, p_valid, r_valid = train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer)\n",
    "    print(\n",
    "        f\"{'':<15}{'Train':^15}{'Valid':^15}\",\n",
    "        f\"{'F1 score':<15}{f_train:^15.3f}{f_valid:^15.3f}\",\n",
    "        f\"{'Precision':<15}{p_train:^15.3f}{p_valid:^15.3f}\",\n",
    "        f\"{'Rappel':<15}{r_train:^15.3f}{r_valid:^15.3f}\",\n",
    "        sep=\"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nApxNet(nn.Module):\n",
    "    def __init__(self, n, hl=3) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_apx = n\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('nets', Parallel(OrderedDict([\n",
    "                (f'apx{i}', ApproxNet(hl)) for i in range(1, self.n_apx+1)\n",
    "            ]))),\n",
    "            ('or_', MaxLayer()),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "    \n",
    "    def forward_apx_only(self, input):\n",
    "        return mtf.maximum([self.net.nets.get_submodule(f\"apx{i}\")(input) for i in range(1, self.n_apx+1)])\n",
    "    \n",
    "    def add_apx(self, module):\n",
    "        self.n_apx += 1\n",
    "        self.net.nets.add_module(f'apx{self.n_apx}', module)\n",
    "    \n",
    "    def add_nn(self, module):\n",
    "        self.net.nets.add_module(f'nn', module)\n",
    "    \n",
    "class ApproxNet(nn.Module):\n",
    "    def __init__(self, hl1):\n",
    "        super().__init__()\n",
    "        self.nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', StepActivation()),\n",
    "            ('l2', nn.Linear(hl1,5)),\n",
    "            ('a2', StepActivation()),\n",
    "            ('l3', nn.Linear(5,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self. nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', nn.ReLU()),\n",
    "            ('l2', nn.Linear(hl1,hl2)),\n",
    "            ('a2', nn.ReLU()),\n",
    "            ('l3', nn.Linear(hl2,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, x_valid, y_valid):\n",
    "    model.eval()\n",
    "    global_pred_valid = model(x_valid).detach()\n",
    "    apx_pred_valid = model.forward_apx_only(x_valid).detach()\n",
    "    nn_pred_valid = model.net.nets.nn(x_valid).detach()\n",
    "\n",
    "    glob_recall = metrics.recall_score(y_valid, global_pred_valid, pos_label=1, average='binary', zero_division=0)\n",
    "    apx_recall = metrics.recall_score(y_valid, apx_pred_valid, pos_label=1, average='binary', zero_division=0)\n",
    "    apx_misszero = 1 - metrics.precision_score(y_valid, apx_pred_valid, pos_label=1, average='binary', zero_division=0)\n",
    "    nn_recall = metrics.recall_score(y_valid, nn_pred_valid, pos_label=1, average='binary', zero_division=0)\n",
    "    relative_recall = apx_recall/glob_recall\n",
    "\n",
    "    glob_prec = metrics.precision_score(y_valid, global_pred_valid, average='micro', zero_division=0)\n",
    "\n",
    "    return glob_recall, apx_recall, apx_misszero, nn_recall, relative_recall, glob_prec\n",
    "\n",
    "def sequential_train(x_train, y_train, x_valid, y_valid, n=1):\n",
    "    epochs = 500\n",
    "    \n",
    "    model = nApxNet(0, hl=5)\n",
    "    criterion = AsymBCELoss(1.2) # HERE\n",
    "    for _ in range(n):\n",
    "        module = ApproxNet(5)\n",
    "        optimizer = Adam(module.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "        model.add_apx(module)\n",
    "\n",
    "        train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "        mtf.freeze_model(model)\n",
    "\n",
    "    module = Net()\n",
    "    model.add_nn(module)\n",
    "    criterion = nn.BCELoss() # CHANGE ???\n",
    "    optimizer = Adam(module.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "\n",
    "    return compute_metrics(model, x_valid, y_valid)\n",
    "\n",
    "def simultaneous_train(x_train, y_train, x_valid, y_valid, n=1):\n",
    "    epochs = 500\n",
    "    \n",
    "    model = nApxNet(n, hl=5)\n",
    "    criterion = AsymBCELoss(1.2) # HERE\n",
    "    model.add_nn(Net())\n",
    "    optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "\n",
    "    return compute_metrics(model, x_valid, y_valid)\n",
    "\n",
    "def separate_train(x_train, y_train, x_valid, y_valid, n=1):\n",
    "    epochs = 500\n",
    "    \n",
    "    model = nApxNet(0, hl=5)\n",
    "    for _ in range(n):\n",
    "        module = ApproxNet(5)\n",
    "        criterion = AsymBCELoss(1.2) # HERE\n",
    "        optimizer = Adam(module.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "        train_model(x_train, y_train, module, criterion, optimizer, epochs)\n",
    "        model.add_apx(module)\n",
    "\n",
    "    net = Net()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = Adam(net.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "    train_model(x_train, y_train, net, criterion, optimizer, epochs)\n",
    "\n",
    "    model.add_nn(net)\n",
    "\n",
    "    return compute_metrics(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQUENTIAL_TRAIN\n",
      "Model cov : 0.786\n",
      "NN cov : 0.513\n",
      "Approx cov : 0.690\n",
      "Approx misclassified zeros : 0.324\n",
      "Relative cov : 0.874\n",
      "Model precision : 0.705\n",
      "SIMULTANEOUS_TRAIN\n",
      "Model cov : 0.765\n",
      "NN cov : 0.640\n",
      "Approx cov : 0.658\n",
      "Approx misclassified zeros : 0.218\n",
      "Relative cov : 0.860\n",
      "Model precision : 0.742\n",
      "SEPARATE_TRAIN\n",
      "Model cov : 0.823\n",
      "NN cov : 0.701\n",
      "Approx cov : 0.684\n",
      "Approx misclassified zeros : 0.305\n",
      "Relative cov : 0.827\n",
      "Model precision : 0.714\n"
     ]
    }
   ],
   "source": [
    "max_iter = 100\n",
    "for func_train in [sequential_train, simultaneous_train, separate_train]:\n",
    "    sum = np.zeros(6) \n",
    "    for _ in range(max_iter):\n",
    "        train_index, valid_index = torch.utils.data.random_split(range(x_data.size(0)), [0.9, 0.1])\n",
    "\n",
    "        x_train, y_train = x_data[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data[valid_index], y_data[valid_index]\n",
    "\n",
    "        res = func_train(x_train, y_train, x_valid, y_valid, 1)\n",
    "        res = np.array(res)\n",
    "        sum+=res\n",
    "\n",
    "    sum/=max_iter\n",
    "    print(func_train.__name__.upper())\n",
    "    print(f\"Model cov : {sum[0]:.3f}\",\n",
    "        f\"NN cov : {sum[3]:.3f}\",\n",
    "        f\"Approx cov : {sum[1]:.3f}\",\n",
    "        f\"Approx misclassified zeros : {sum[2]:.3f}\", # number of zeros predicted as one / number predicted as one\n",
    "        f\"Relative cov : {sum[4]:.3f}\",\n",
    "        f\"Model precision : {sum[5]:.3f}\",\n",
    "        sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(pred_train, y_train, pred_valid, y_valid):\n",
    "#     p_train, r_train, f_train, _ = metrics.precision_recall_fscore_support(y_train, pred_train, beta=1, average=None, labels=[0,1])\n",
    "#     p_valid, r_valid, f_valid, _ = metrics.precision_recall_fscore_support(y_valid, pred_valid, beta=1, average=None, labels=[0,1])\n",
    "\n",
    "#     metrics_list = [\n",
    "#         f_train.mean(), f_valid.mean(),\n",
    "#         p_train[0], p_valid[0],\n",
    "#         r_train[0], r_valid[0],\n",
    "#         p_train[1], p_valid[1],\n",
    "#         r_train[1], r_valid[1],\n",
    "#     ]\n",
    "\n",
    "#     return metrics_list\n",
    "\n",
    "# net = Net()\n",
    "# crit = nn.BCELoss()\n",
    "# opt = Adam(net.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "# train_model(x_train, y_train, net, crit, opt, max_epoch=500)\n",
    "\n",
    "# net_pred_train = net(x_train).detach().round()\n",
    "# net_pred_valid = net(x_valid).detach().round()\n",
    "\n",
    "# net_metrics = compute_metrics(net_pred_train, y_train, net_pred_valid, y_valid)\n",
    "\n",
    "# print(net_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
