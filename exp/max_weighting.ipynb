{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam\n",
    "from sklearn import metrics\n",
    "from collections import OrderedDict \n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import datasets\n",
    "import utils.more_torch_functions as mtf\n",
    "from utils.modules import Parallel, MaxLayer\n",
    "from utils.custom_activations import StepActivation\n",
    "from utils.custom_loss import AsymBCELoss\n",
    "from utils.misc import train_model\n",
    "\n",
    "seed = 2872\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "SAVE_PATH = os.path.join(os.path.abspath('..'), \"backup\")\n",
    "PKL_PATH = os.path.join(SAVE_PATH, \"bdd\")\n",
    "PTH_PATH = os.path.join(SAVE_PATH, \"nn\")\n",
    "METRIC_PATH = os.path.join(SAVE_PATH, \"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 29])\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.DiabetesDataset\n",
    "\n",
    "np_x, np_y = dataset.get_dataset(balancing=True, discretizing=True, hot_encoding=True)\n",
    "x_data, y_data = torch.Tensor(np_x), torch.Tensor(np_y)\n",
    "input_size = x_data.size(1)\n",
    "print(x_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(x_train, y_train, x_valid, y_valid, model, metrics_average=\"binary\"):\n",
    "    model.eval()\n",
    "    pred_train = model(x_train).detach()\n",
    "    pred_valid = model(x_valid).detach()\n",
    "\n",
    "    p_train, r_train, f_train, _ = metrics.precision_recall_fscore_support(y_train, pred_train, beta=1, average=metrics_average, labels=[0,1])\n",
    "    p_valid, r_valid, f_valid, _ = metrics.precision_recall_fscore_support(y_valid, pred_valid, beta=1, average=metrics_average, labels=[0,1])\n",
    "\n",
    "    return f_train, p_train, r_train, f_valid, p_valid, r_valid\n",
    "\n",
    "def train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer, epochs=50, metrics_average=\"binary\"):\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "    return eval_model(x_train, y_train, x_valid, y_valid, model, metrics_average)\n",
    "\n",
    "def print_eval(x_train, y_train, x_valid, y_valid, model, criterion, optimizer):\n",
    "    f_train, p_train, r_train, f_valid, p_valid, r_valid = train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer)\n",
    "    print(\n",
    "        f\"{'':<15}{'Train':^15}{'Valid':^15}\",\n",
    "        f\"{'F1 score':<15}{f_train:^15.3f}{f_valid:^15.3f}\",\n",
    "        f\"{'Precision':<15}{p_train:^15.3f}{p_valid:^15.3f}\",\n",
    "        f\"{'Rappel':<15}{r_train:^15.3f}{r_valid:^15.3f}\",\n",
    "        sep=\"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nApxNet(nn.Module):\n",
    "    def __init__(self, n, hl=3, max_weighting=\"all\") -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_apx = n\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('nets', Parallel(OrderedDict([\n",
    "                (f'apx{i}', ApproxNet(hl)) for i in range(1, self.n_apx+1)\n",
    "            ]))),\n",
    "            ('or_', MaxLayer(backward_method=max_weighting)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "    \n",
    "    def forward_apx_only(self, input):\n",
    "        return mtf.maximum([self.net.nets.get_submodule(f\"apx{i}\")(input) for i in range(1, self.n_apx+1)])\n",
    "    \n",
    "    def add_apx(self, module):\n",
    "        self.n_apx += 1\n",
    "        self.net.nets.add_module(f'apx{self.n_apx}', module)\n",
    "    \n",
    "    def add_nn(self, module):\n",
    "        self.net.nets.add_module(f'nn', module)\n",
    "    \n",
    "class ApproxNet(nn.Module):\n",
    "    def __init__(self, hl1):\n",
    "        super().__init__()\n",
    "        self.nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', StepActivation()),\n",
    "            ('l2', nn.Linear(hl1,5)),\n",
    "            ('a2', StepActivation()),\n",
    "            ('l3', nn.Linear(5,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self. nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', nn.ReLU()),\n",
    "            ('l2', nn.Linear(hl1,hl2)),\n",
    "            ('a2', nn.ReLU()),\n",
    "            ('l3', nn.Linear(hl2,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, x_valid, y_valid):\n",
    "    model.eval()\n",
    "    global_pred_valid = model(x_valid).detach()\n",
    "    apx_pred_valid = model.forward_apx_only(x_valid).detach()\n",
    "    nn_pred_valid = model.net.nets.nn(x_valid).detach()\n",
    "\n",
    "    glob_recall = metrics.recall_score(y_valid, global_pred_valid, pos_label=1, average='binary', zero_division=0)\n",
    "    apx_recall = metrics.recall_score(y_valid, apx_pred_valid, pos_label=1, average='binary', zero_division=0)\n",
    "    apx_misszero = 1 - metrics.precision_score(y_valid, apx_pred_valid, pos_label=1, average='binary', zero_division=0)\n",
    "    nn_recall = metrics.recall_score(y_valid, nn_pred_valid, pos_label=1, average='binary', zero_division=0)\n",
    "    relative_recall = apx_recall/glob_recall\n",
    "\n",
    "    glob_prec = metrics.precision_score(y_valid, global_pred_valid, average='micro', zero_division=0)\n",
    "\n",
    "    return glob_recall, apx_recall, apx_misszero, nn_recall, relative_recall, glob_prec\n",
    "\n",
    "def sequential_train(x_train, y_train, x_valid, y_valid, epochs=500, n=1, max_weighting=\"all\"):   \n",
    "    model = nApxNet(0, hl=5, max_weighting=max_weighting)\n",
    "    criterion = AsymBCELoss(2) # HERE\n",
    "    for _ in range(n):\n",
    "        module = ApproxNet(5)\n",
    "        optimizer = Adam(module.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "        model.add_apx(module)\n",
    "\n",
    "        train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "        mtf.freeze_model(model)\n",
    "\n",
    "    module = Net()\n",
    "    model.add_nn(module)\n",
    "    criterion = nn.BCELoss() # CHANGE ???\n",
    "    optimizer = Adam(module.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "\n",
    "    return compute_metrics(model, x_valid, y_valid)\n",
    "\n",
    "def simultaneous_train(x_train, y_train, x_valid, y_valid, epochs=500, n=1, max_weighting=\"all\"):    \n",
    "    model = nApxNet(n, hl=5, max_weighting=max_weighting)\n",
    "    criterion = AsymBCELoss(2) # HERE\n",
    "    model.add_nn(Net())\n",
    "    optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "\n",
    "    return compute_metrics(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQUENTIAL_TRAIN ALL\n",
      "Model cov : 0.808\n",
      "NN cov : 0.631\n",
      "Approx cov : 0.719\n",
      "Approx misclassified zeros : 0.272\n",
      "Relative cov : 0.888\n",
      "Model precision : 0.728\n",
      "\n",
      "SIMULTANEOUS_TRAIN ALL\n",
      "Model cov : 0.812\n",
      "NN cov : 0.341\n",
      "Approx cov : 0.734\n",
      "Approx misclassified zeros : 0.339\n",
      "Relative cov : 0.892\n",
      "Model precision : 0.727\n",
      "\n",
      "SEQUENTIAL_TRAIN MAX\n",
      "Model cov : 0.659\n",
      "NN cov : 0.000\n",
      "Approx cov : 0.659\n",
      "Approx misclassified zeros : 0.262\n",
      "Relative cov : 1.000\n",
      "Model precision : 0.701\n",
      "\n",
      "SIMULTANEOUS_TRAIN MAX\n",
      "Model cov : 0.696\n",
      "NN cov : 0.495\n",
      "Approx cov : 0.236\n",
      "Approx misclassified zeros : 0.560\n",
      "Relative cov : 0.339\n",
      "Model precision : 0.713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "max_iter = 100\n",
    "for wieghting_method in [\"all\", \"max\"]:\n",
    "    for func_train in [sequential_train, simultaneous_train]:\n",
    "        sum = np.zeros(6) \n",
    "        for _ in range(max_iter):\n",
    "            train_index, valid_index = torch.utils.data.random_split(range(x_data.size(0)), [0.9, 0.1])\n",
    "\n",
    "            x_train, y_train = x_data[train_index], y_data[train_index]\n",
    "            x_valid, y_valid = x_data[valid_index], y_data[valid_index]\n",
    "\n",
    "            res = func_train(x_train, y_train, x_valid, y_valid, n=3, max_weighting=wieghting_method)\n",
    "            res = np.array(res)\n",
    "            sum+=res\n",
    "\n",
    "        sum/=max_iter\n",
    "        print(func_train.__name__.upper(), wieghting_method.upper())\n",
    "        results[(func_train.__name__.upper(), wieghting_method.upper())] = sum.copy()\n",
    "        print(f\"Model cov : {sum[0]:.3f}\",\n",
    "            f\"NN cov : {sum[3]:.3f}\",\n",
    "            f\"Approx cov : {sum[1]:.3f}\",\n",
    "            f\"Approx misclassified zeros : {sum[2]:.3f}\", # number of zeros predicted as one / number predicted as one\n",
    "            f\"Relative cov : {sum[4]:.3f}\",\n",
    "            f\"Model precision : {sum[5]:.3f}\",\n",
    "            sep='\\n', end=\"\\n\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('SEQUENTIAL_TRAIN', 'ALL'): array([0.80788612, 0.71884743, 0.27201542, 0.63146051, 0.88773641,\n",
      "       0.72754717]), ('SIMULTANEOUS_TRAIN', 'ALL'): array([0.81235637, 0.73426092, 0.33901588, 0.34148472, 0.89210092,\n",
      "       0.72698113]), ('SEQUENTIAL_TRAIN', 'MAX'): array([0.65866333, 0.65866333, 0.26226979, 0.        , 1.        ,\n",
      "       0.70132075]), ('SIMULTANEOUS_TRAIN', 'MAX'): array([0.69636098, 0.23619374, 0.55980637, 0.49500196, 0.3392874 ,\n",
      "       0.71339623])}\n",
      "0.81 & 0.66 & 0.81 & 0.70\n",
      "0.72 & 0.66 & 0.73 & 0.24\n",
      "0.27 & 0.26 & 0.34 & 0.56\n",
      "0.63 & 0.00 & 0.34 & 0.50\n",
      "0.89 & 1.00 & 0.89 & 0.34\n",
      "0.73 & 0.70 & 0.73 & 0.71\n"
     ]
    }
   ],
   "source": [
    "# 0: model cov, 1: apx cov, 2: apx miss, 3: nn cov, 4: relative cov, 5: model precision\n",
    "print(results)\n",
    "rbis = {k: list(v) for k, v in results.items()}\n",
    "a, b, c, d = list(rbis.values())\n",
    "values = [a, c, b, d]\n",
    "for x in zip(*values):\n",
    "    print(\" & \".join([f\"{a:.2f}\" for a in x]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
