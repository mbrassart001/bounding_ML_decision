{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam\n",
    "from sklearn import metrics\n",
    "from collections import OrderedDict \n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import datasets\n",
    "import utils.more_torch_functions as mtf\n",
    "from utils.modules import Parallel, MaxLayer\n",
    "from utils.custom_activations import StepActivation\n",
    "from utils.custom_loss import AsymBCELoss\n",
    "from utils.misc import train_model, Figures\n",
    "from compiling_nn.build_odd import compile_nn\n",
    "from compiling_nn.utils_odd import pickle_bdd, unpickle_bdd\n",
    "\n",
    "seed = 2872\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "SAVE_PATH = os.path.join(os.path.abspath('..'), \"backup\")\n",
    "PKL_PATH = os.path.join(SAVE_PATH, \"bdd\")\n",
    "PTH_PATH = os.path.join(SAVE_PATH, \"nn\")\n",
    "METRIC_PATH = os.path.join(SAVE_PATH, \"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 29])\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.DiabetesDataset\n",
    "\n",
    "np_x, np_y = dataset.get_dataset(balancing=True, discretizing=True, hot_encoding=True)\n",
    "x_data, y_data = torch.Tensor(np_x), torch.Tensor(np_y)\n",
    "input_size = x_data.size(1)\n",
    "print(x_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer, epochs=50, metrics_average=\"binary\"):\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "    model.eval()\n",
    "    pred_train = model(x_train).detach()\n",
    "    pred_valid = model(x_valid).detach()\n",
    "\n",
    "    p_train, r_train, f_train, _ = metrics.precision_recall_fscore_support(y_train, pred_train, beta=1, average=metrics_average, labels=[0,1])\n",
    "    p_valid, r_valid, f_valid, _ = metrics.precision_recall_fscore_support(y_valid, pred_valid, beta=1, average=metrics_average, labels=[0,1])\n",
    "\n",
    "    return f_train, p_train, r_train, f_valid, p_valid, r_valid\n",
    "\n",
    "def print_eval(x_train, y_train, x_valid, y_valid, model, criterion, optimizer):\n",
    "    f_train, p_train, r_train, f_valid, p_valid, r_valid = train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer)\n",
    "    print(\n",
    "        f\"{'':<15}{'Train':^15}{'Valid':^15}\",\n",
    "        f\"{'F1 score':<15}{f_train:^15.3f}{f_valid:^15.3f}\",\n",
    "        f\"{'Precision':<15}{p_train:^15.3f}{p_valid:^15.3f}\",\n",
    "        f\"{'Rappel':<15}{r_train:^15.3f}{r_valid:^15.3f}\",\n",
    "        sep=\"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nApxNet(nn.Module):\n",
    "    def __init__(self, n, hl=3) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_apx = n\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('nets', Parallel(OrderedDict([\n",
    "                (f'apx{i}', ApproxNet(hl)) for i in range(1, self.n_apx+1)\n",
    "            ]))),\n",
    "            ('or_', MaxLayer()),\n",
    "        ]))\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "    \n",
    "    def add_apx(self, module):\n",
    "        self.n_apx += 1\n",
    "        self.net.nets.add_module(f'apx{self.n_apx}', module)\n",
    "    \n",
    "class ApproxNet(nn.Module):\n",
    "    def __init__(self, hl1):\n",
    "        super().__init__()\n",
    "        self.nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', StepActivation()),\n",
    "            ('l2', nn.Linear(hl1,5)),\n",
    "            ('a2', StepActivation()),\n",
    "            ('l3', nn.Linear(5,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self. nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', nn.ReLU()),\n",
    "            ('l2', nn.Linear(hl1,hl2)),\n",
    "            ('a2', nn.ReLU()),\n",
    "            ('l3', nn.Linear(hl2,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_approx(x_train, y_train, x_valid, y_valid):\n",
    "    exp_folder = \"nn_approx\"\n",
    "    os.makedirs(os.path.join(PTH_PATH, exp_folder), exist_ok=True)\n",
    "    d_metrics = dict()\n",
    "    model = nApxNet(1, hl=5)\n",
    "    criterion = AsymBCELoss() # HERE\n",
    "    module = model.net.nets.apx1\n",
    "    optimizer = Adam(module.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "    f1t, pt, rt, f1v , pv, rv = train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer, epochs=500, metrics_average=None)\n",
    "\n",
    "    mtf.freeze_model(model)\n",
    "\n",
    "    module = Net()\n",
    "    model.add_apx(module)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = Adam(module.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "    f1t, pt, rt, f1v , pv, rv = train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer, epochs=500, metrics_average=None)\n",
    "\n",
    "    d_metrics[('train', 'f1')] = f1t.mean()\n",
    "    d_metrics[('valid', 'f1')] = f1v.mean()\n",
    "    d_metrics[('train', 'precision0')] = pt[0]\n",
    "    d_metrics[('valid', 'precision0')] = pv[0]\n",
    "    d_metrics[('train', 'recall0')] = rt[0]\n",
    "    d_metrics[('valid', 'recall0')] = rv[0]\n",
    "    d_metrics[('train', 'precision1')] = pt[1]\n",
    "    d_metrics[('valid', 'precision1')] = pv[1]\n",
    "    d_metrics[('train', 'recall1')] = rt[1]\n",
    "    d_metrics[('valid', 'recall1')] = rv[1]\n",
    "\n",
    "    with open(os.path.join(METRIC_PATH, f\"{exp_folder}.pkl\"), 'wb') as f:\n",
    "        pickle.dump(d_metrics, f)\n",
    "    return d_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, valid_index = torch.utils.data.random_split(range(x_data.size(0)), [0.9, 0.1])\n",
    "\n",
    "x_train, y_train = x_data[train_index], y_data[train_index]\n",
    "x_valid, y_valid = x_data[valid_index], y_data[valid_index]\n",
    "\n",
    "d_metrics = nn_approx(x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('train', 'f1'): 0.8859327834290156, ('valid', 'f1'): 0.7239583333333333, ('train', 'precision0'): 0.9400921658986175, ('valid', 'precision0'): 0.7, ('train', 'recall0'): 0.8292682926829268, ('valid', 'recall0'): 0.6363636363636364, ('train', 'precision1'): 0.8421052631578947, ('valid', 'precision1'): 0.7575757575757576, ('train', 'recall1'): 0.9451476793248945, ('valid', 'recall1'): 0.8064516129032258}\n"
     ]
    }
   ],
   "source": [
    "print(d_metrics, sep='\\n')\n",
    "# train / valid\n",
    "# f1 p0 r0 p1 r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9668622002675723, 0.7668621700879765, 0.967479674796748, 0.7272727272727273, 0.967479674796748, 0.7272727272727273, 0.9662447257383966, 0.8064516129032258, 0.9662447257383966, 0.8064516129032258]\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(pred_train, y_train, pred_valid, y_valid):\n",
    "    p_train, r_train, f_train, _ = metrics.precision_recall_fscore_support(y_train, pred_train, beta=1, average=None, labels=[0,1])\n",
    "    p_valid, r_valid, f_valid, _ = metrics.precision_recall_fscore_support(y_valid, pred_valid, beta=1, average=None, labels=[0,1])\n",
    "\n",
    "    metrics_list = [\n",
    "        f_train.mean(), f_valid.mean(),\n",
    "        p_train[0], p_valid[0],\n",
    "        r_train[0], r_valid[0],\n",
    "        p_train[1], p_valid[1],\n",
    "        r_train[1], r_valid[1],\n",
    "    ]\n",
    "\n",
    "    return metrics_list\n",
    "\n",
    "net = Net()\n",
    "crit = nn.BCELoss()\n",
    "opt = Adam(net.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "train_model(x_train, y_train, net, crit, opt, max_epoch=500)\n",
    "\n",
    "net_pred_train = net(x_train).detach().round()\n",
    "net_pred_valid = net(x_valid).detach().round()\n",
    "\n",
    "net_metrics = compute_metrics(net_pred_train, y_train, net_pred_valid, y_valid)\n",
    "\n",
    "print(net_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
