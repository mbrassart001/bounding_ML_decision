{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import OrderedDict \n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import datasets\n",
    "import utils.more_torch_functions as mtf\n",
    "from utils.modules import Parallel, MaxLayer\n",
    "from utils.custom_activations import StepActivation\n",
    "from utils.custom_loss import AsymBCELoss\n",
    "from utils.misc import train_model\n",
    "from utils.test import Model\n",
    "\n",
    "seed = 2872\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "SAVE_PATH = os.path.join(os.path.abspath('..'), \"backup\")\n",
    "PKL_PATH = os.path.join(SAVE_PATH, \"bdd\")\n",
    "PTH_PATH = os.path.join(SAVE_PATH, \"nn\")\n",
    "METRIC_PATH = os.path.join(SAVE_PATH, \"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([536, 29])\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.DiabetesDataset\n",
    "\n",
    "np_x, np_y = dataset.get_dataset(balancing=True, discretizing=True, hot_encoding=True)\n",
    "x_data, y_data = torch.Tensor(np_x), torch.Tensor(np_y)\n",
    "input_size = x_data.size(1)\n",
    "print(x_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(x_train, y_train, x_valid, y_valid, model, metrics_average=\"binary\"):\n",
    "    model.eval()\n",
    "    pred_train = model(x_train).detach()\n",
    "    pred_valid = model(x_valid).detach()\n",
    "\n",
    "    p_train, r_train, f_train, _ = metrics.precision_recall_fscore_support(y_train, pred_train, beta=1, average=metrics_average, labels=[0,1])\n",
    "    p_valid, r_valid, f_valid, _ = metrics.precision_recall_fscore_support(y_valid, pred_valid, beta=1, average=metrics_average, labels=[0,1])\n",
    "\n",
    "    return f_train, p_train, r_train, f_valid, p_valid, r_valid\n",
    "\n",
    "def train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer, epochs=50, metrics_average=\"binary\"):\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "    return eval_model(x_train, y_train, x_valid, y_valid, model, metrics_average)\n",
    "\n",
    "def print_eval(x_train, y_train, x_valid, y_valid, model, criterion, optimizer):\n",
    "    f_train, p_train, r_train, f_valid, p_valid, r_valid = train_eval_model(x_train, y_train, x_valid, y_valid, model, criterion, optimizer)\n",
    "    print(\n",
    "        f\"{'':<15}{'Train':^15}{'Valid':^15}\",\n",
    "        f\"{'F1 score':<15}{f_train:^15.3f}{f_valid:^15.3f}\",\n",
    "        f\"{'Precision':<15}{p_train:^15.3f}{p_valid:^15.3f}\",\n",
    "        f\"{'Rappel':<15}{r_train:^15.3f}{r_valid:^15.3f}\",\n",
    "        sep=\"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nApxNet(nn.Module):\n",
    "    def __init__(self, n, hl=3, max_weighting=\"all\") -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_apx = n\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('nets', Parallel(OrderedDict([\n",
    "                (f'apx{i}', ApproxNet(hl)) for i in range(1, self.n_apx+1)\n",
    "            ]))),\n",
    "            ('or_', MaxLayer(backward_method=max_weighting)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "    \n",
    "    def forward_apx_only(self, input):\n",
    "        return mtf.maximum([self.net.nets.get_submodule(f\"apx{i}\")(input) for i in range(1, self.n_apx+1)])\n",
    "    \n",
    "    def add_apx(self, module):\n",
    "        self.n_apx += 1\n",
    "        self.net.nets.add_module(f'apx{self.n_apx}', module)\n",
    "    \n",
    "    def add_nn(self, module):\n",
    "        self.net.nets.add_module(f'nn', module)\n",
    "    \n",
    "class ApproxNet(nn.Module):\n",
    "    def __init__(self, hl1):\n",
    "        super().__init__()\n",
    "        self.nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', StepActivation()),\n",
    "            ('l2', nn.Linear(hl1,5)),\n",
    "            ('a2', StepActivation()),\n",
    "            ('l3', nn.Linear(5,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self. nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', nn.ReLU()),\n",
    "            ('l2', nn.Linear(hl1,hl2)),\n",
    "            ('a2', nn.ReLU()),\n",
    "            ('l3', nn.Linear(hl2,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class NN_Model(Model):\n",
    "    def forward(self, x):\n",
    "        x = super().forward(x)\n",
    "\n",
    "        if not self.training:\n",
    "            x = x.round()\n",
    "        \n",
    "        return x\n",
    "\n",
    "class RandomForest(RandomForestClassifier):\n",
    "    def eval(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.predict(x)\n",
    "        return torch.Tensor(x)\n",
    "\n",
    "def compute_metrics(model, x_valid, y_valid):\n",
    "    model.eval()\n",
    "    global_pred_valid = model(x_valid).detach()\n",
    "    # apx_pred_valid = model.forward_apx_only(x_valid).detach()\n",
    "    # nn_pred_valid = model.net.nets.nn(x_valid).detach()\n",
    "\n",
    "    p_valid, r_valid, f_valid, _ = metrics.precision_recall_fscore_support(y_valid, global_pred_valid, beta=1, average=None, labels=[0,1], zero_division=0)\n",
    "\n",
    "    return f_valid.mean(), p_valid[0], p_valid[1], r_valid[0], r_valid[1]\n",
    "\n",
    "def nn_train(x_train, y_train, x_valid, y_valid, epochs=500):\n",
    "    model = NN_Model(input_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "\n",
    "    return compute_metrics(model, x_valid, y_valid)\n",
    "\n",
    "def rf_train(x_train, y_train, x_valid, y_valid):\n",
    "    model = RandomForest()\n",
    "\n",
    "    model.fit(x_train, y_train.reshape(-1))\n",
    "\n",
    "    return compute_metrics(model, x_valid, y_valid)\n",
    "\n",
    "def apx_train(x_train, y_train, x_valid, y_valid, epochs=500, n=3, p=1):   \n",
    "    model = nApxNet(0, hl=5)\n",
    "    criterion = AsymBCELoss(p) # HERE\n",
    "    for _ in range(n):\n",
    "        module = ApproxNet(5)\n",
    "        optimizer = Adam(module.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "        model.add_apx(module)\n",
    "\n",
    "        train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "        mtf.freeze_model(model)\n",
    "\n",
    "    module = Net()\n",
    "    model.add_nn(module)\n",
    "    criterion = nn.BCELoss() # CHANGE ???\n",
    "    optimizer = Adam(module.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "    train_model(x_train, y_train, model, criterion, optimizer, epochs)\n",
    "\n",
    "    return compute_metrics(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APX_TRAIN\n",
      "0.69 & 0.75 & 0.68 & 0.59 & 0.80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_iter = 100\n",
    "for train_func in [apx_train]:\n",
    "    sum = np.zeros(5) \n",
    "    for _ in range(max_iter):\n",
    "        train_index, valid_index = torch.utils.data.random_split(range(x_data.size(0)), [0.9, 0.1])\n",
    "\n",
    "        x_train, y_train = x_data[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data[valid_index], y_data[valid_index]\n",
    "\n",
    "        res = train_func(x_train, y_train, x_valid, y_valid)\n",
    "        res = np.array(res)\n",
    "        sum+=res\n",
    "\n",
    "    sum/=max_iter\n",
    "    print(train_func.__name__.upper())\n",
    "    print(f\"{sum[0]:.2f} & {sum[1]:.2f} & {sum[2]:.2f} & {sum[3]:.2f} & {sum[4]:.2f}\", end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
