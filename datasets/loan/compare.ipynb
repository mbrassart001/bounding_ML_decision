{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict \n",
    "from sklearn import metrics, model_selection\n",
    "from torch.autograd import Function\n",
    "from torch.optim import Adam\n",
    "from graphviz import Source\n",
    "from pyeda.boolalg.bdd import bdd2expr\n",
    "\n",
    "filepath = os.path.abspath('')\n",
    "sys.path.append(os.path.join(filepath, \"..\", \"..\", \"compiling_nn\"))\n",
    "from build_odd import compile_nn\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics, Activations, Loss and Networks definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(y_true, y_pred):\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix, display_labels=[False, True])\n",
    "    return cm_display\n",
    "\n",
    "def plot_cm(y_true, y_pred):\n",
    "    cm_display = cm(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4,8))\n",
    "    cm_display.plot(ax=ax, colorbar=False)\n",
    "\n",
    "def plot_combine_cm(cms, titles=None):\n",
    "    n = len(cms)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(4*n, 8))\n",
    "    if titles:\n",
    "        for ax, cm, title in zip(axs, cms, titles):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "            ax.set_title(title)\n",
    "    else:\n",
    "        for ax, cm in zip(axs, cms):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "    fig.tight_layout()\n",
    "\n",
    "def cov_score(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    scores = {}\n",
    "\n",
    "    for label in labels:\n",
    "        indices_true = np.where(y_true == label)[0]\n",
    "        indices_pred = np.where(y_pred == label)[0]\n",
    "        scores[label] = len(np.intersect1d(indices_true, indices_pred))/len(indices_true)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def cross_valid(X, Y, train_func, skf, **kw_train):\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        model, y_pred = train_func(x_train, y_train, **kw_train)\n",
    "        model.eval()\n",
    "        yield y_pred.detach().round(), y_train, model(x_test).detach(), y_test\n",
    "\n",
    "def tnot(a): return torch.logical_not(a)\n",
    "def tor(a,b): return torch.logical_or(a,b)\n",
    "def tand(a,b): return torch.logical_and(a,b)\n",
    "def txor(a,b): return torch.logical_xor(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = torch.where(input>=0, torch.tensor(1.0), torch.tensor(0.0))\n",
    "        ctx.save_for_backward(input)\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = torch.zeros_like(input)\n",
    "        return grad_input\n",
    "    \n",
    "class StepActivation(nn.Module):\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            return torch.sigmoid(input)\n",
    "        else:\n",
    "            return StepFunction.apply(input)\n",
    "    \n",
    "class AsymMSELoss(nn.Module): # https://www.desmos.com/calculator/zmxcluqhkt\n",
    "    def __init__(self, p=2):\n",
    "        super(AsymMSELoss, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        dif = label - input\n",
    "        a = torch.square(dif)\n",
    "        b = a*self.p\n",
    "        loss = torch.where(dif < 0, b, a)\n",
    "        loss = torch.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "class AsymBCELoss(nn.Module):\n",
    "    def __init__(self, p=2):\n",
    "        super(AsymBCELoss, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        loss = -torch.maximum(label*torch.log(input) + self.p*(1-label)*torch.log(1-input), torch.full(input.size(), -100))\n",
    "        loss = torch.mean(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproxNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        hl1 = 10\n",
    "\n",
    "        self.nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(25,hl1)),\n",
    "            ('a1', StepActivation()),\n",
    "            ('l2', nn.Linear(hl1,1)),\n",
    "            ('a2', StepActivation())\n",
    "        ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CentralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 50\n",
    "\n",
    "        self. nn = nn.Sequential(\n",
    "            nn.Linear(25,hl1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl1,hl2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl2,1),\n",
    "            StepActivation(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class BoundNetResults():\n",
    "    def __init__(self, x, xhi, xnn, xlo):\n",
    "        self.x = x\n",
    "        self.hi = xhi\n",
    "        self.nn = xnn\n",
    "        self.lo = xlo\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if hasattr(self.x, name):\n",
    "            return getattr(self.x, name)\n",
    "        else:\n",
    "            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
    "    \n",
    "    def __dir__(self):\n",
    "        return dir(self.x)\n",
    "    \n",
    "    def detach(self):\n",
    "        self.x = self.x.detach()\n",
    "        self.hi = self.hi.detach()\n",
    "        self.nn = self.nn.detach()\n",
    "        self.lo = self.lo.detach()\n",
    "        return self\n",
    "    \n",
    "    def round(self, *args):\n",
    "        self.x = self.x.round(*args)\n",
    "        self.hi = self.hi.round(*args)\n",
    "        self.nn = self.nn.round(*args)\n",
    "        self.lo = self.lo.round(*args)\n",
    "        return self\n",
    "\n",
    "class BoundNetLoss():\n",
    "    def __init__(self, hi, nn, lo):\n",
    "        self.hi_loss_fn = hi\n",
    "        self.nn_loss_fn = nn\n",
    "        self.lo_loss_fn = lo\n",
    "\n",
    "    def __call__(self, pred, true):\n",
    "        self.nn_loss = self.nn_loss_fn(pred.nn, true)\n",
    "\n",
    "        target = pred.nn.detach()\n",
    "        self.hi_loss = self.hi_loss_fn(pred.hi, target)\n",
    "        self.lo_loss = self.lo_loss_fn(pred.lo, target)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def backward(self):\n",
    "        self.nn_loss.backward()\n",
    "        self.hi_loss.backward()\n",
    "        self.lo_loss.backward()\n",
    "\n",
    "class BoundNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # high approx nn (bigger = very long to compute into ODD)\n",
    "        self.hi = ApproxNet()\n",
    "\n",
    "        # low approx nn\n",
    "        self.lo = ApproxNet()\n",
    "\n",
    "        # nn to approximate (can make it bigger easily)\n",
    "        self.nn = CentralNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        xhi = self.hi(x)\n",
    "        xnn = self.nn(x)\n",
    "        xlo = self.lo(x)\n",
    "        x = torch.where(xhi>0.5, xhi, torch.where(xlo<0.5, xlo, xnn))\n",
    "        \n",
    "        x = BoundNetResults(x, xhi, xnn, xlo)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 50\n",
    "\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Linear(25,hl1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl1,hl2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl2,1),\n",
    "            StepActivation(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan_Status_Y\n",
      "0                184\n",
      "1                184\n",
      "dtype: int64\n",
      "torch.Size([368, 25]) torch.Size([368, 1])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"loan_data_set.csv\", sep=\",\")\n",
    "df = df.drop(columns=[\"Loan_ID\"])\n",
    "\n",
    "# Remove above 98.5th percentile for 'ApplicantIncome' and 'CoapplicantIncome'\n",
    "df_rank = df[[\"ApplicantIncome\", \"CoapplicantIncome\"]]\n",
    "df_rank[\"rankA\"] = df_rank[[\"ApplicantIncome\"]].rank(pct=True)\n",
    "df_rank[\"rankCo\"] = df_rank[\"CoapplicantIncome\"].rank(pct=True)\n",
    "\n",
    "df = df.loc[(df_rank[\"rankA\"]<=0.985) & (df_rank[\"rankCo\"]<=0.985)]\n",
    "df.index = range(len(df))\n",
    "\n",
    "# Transform using hot encoding\n",
    "df_y = pd.get_dummies(df[[\"Loan_Status\"]], drop_first=True)\n",
    "df_x = df.drop(columns=[\"Loan_Status\"])\n",
    "\n",
    "nunique = df_x.nunique(axis=0)\n",
    "df_x_mean = df_x.mean(axis=0, numeric_only=True)\n",
    "\n",
    "for col, n in nunique.items():\n",
    "    if n > 4:\n",
    "        df_x[col] = df_x[col].apply(lambda x : min(4, x//(.5*df_x_mean[col])))\n",
    "\n",
    "df_x = pd.get_dummies(df_x, columns=df_x.columns, drop_first=True)\n",
    "\n",
    "# Balance dataset\n",
    "itrue = df_y.index[df_y[\"Loan_Status_Y\"]==1].tolist()\n",
    "ifalse = df_y.index[df_y[\"Loan_Status_Y\"]==0].tolist()\n",
    "\n",
    "swap = len(itrue) > len(ifalse)\n",
    "if swap:\n",
    "    itrue,ifalse=ifalse,itrue\n",
    "\n",
    "ifalse = random.choices(ifalse, k=len(itrue))\n",
    "\n",
    "if swap:\n",
    "    itrue,ifalse=ifalse,itrue\n",
    "\n",
    "print(df_y.iloc[itrue+ifalse].value_counts())\n",
    "\n",
    "x_data=torch.Tensor(df_x.iloc[itrue+ifalse].to_numpy(dtype=int))\n",
    "y_data=torch.Tensor(df_y.iloc[itrue+ifalse].to_numpy(dtype=int))\n",
    "\n",
    "print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, model, loss_fn, optimizer, max_epoch):\n",
    "    for _ in range(max_epoch):\n",
    "        model.train()\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # loss with true y values\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, y_pred\n",
    "\n",
    "def train_boundnet(x, y, max_epoch=5000, learning_rate=1e-2):\n",
    "    model = BoundNet()\n",
    "    loss_fn = BoundNetLoss(AsymBCELoss(100), nn.BCELoss(), AsymBCELoss(.001))\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    return train_model(x, y, model, loss_fn, optimizer, max_epoch=max_epoch)\n",
    "\n",
    "def train_simplenet(x, y, max_epoch=5000, learning_rate=1e-2):\n",
    "    model = SimpleNet()\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    return train_model(x, y, model, loss_fn, optimizer, max_epoch=max_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def show_activation(act, output):\n",
    "    # Mean activation per output\n",
    "    act_ones  = torch.where(output==1, act, torch.zeros(act.size()))\n",
    "    act_zeros = torch.where(output==0, act, torch.zeros(act.size()))\n",
    "\n",
    "    mean_ones  = torch.mean(act_ones, dim=0)\n",
    "    mean_zeros = torch.mean(act_zeros, dim=0)\n",
    "\n",
    "    # Figure initialization\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    tick_kw = {'left': False, 'bottom': False, 'labelleft': False}\n",
    "\n",
    "    # Normalize cmap accross both images\n",
    "    min_act = min(mean_ones.min().item(), mean_zeros.min().item())\n",
    "    max_act = max(mean_ones.max().item(), mean_zeros.max().item())\n",
    "\n",
    "    color_map = 'PRGn'\n",
    "\n",
    "    ax[0].imshow(mean_zeros.unsqueeze(0), cmap=color_map, vmin=min_act, vmax=max_act)\n",
    "    ax[0].tick_params(**tick_kw)\n",
    "    ax[0].set_title(\"activation moyenne de la couche cachée avec 0 en sortie\")\n",
    "\n",
    "    ax[1].imshow(mean_ones.unsqueeze(0), cmap=color_map, vmin=min_act, vmax=max_act)\n",
    "    ax[1].tick_params(**tick_kw)\n",
    "    ax[1].set_title(\"activation moyenne de la couche cachée avec 1 en sortie\")\n",
    "\n",
    "    # Show text on cells\n",
    "    for i, (v0, v1) in enumerate(zip(mean_zeros, mean_ones)):\n",
    "        ax[0].text(i, 0, f\"{v0.item():.2f}\", ha=\"center\", va=\"center\")\n",
    "        ax[1].text(i, 0, f\"{v1.item():.2f}\", ha=\"center\", va=\"center\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_activation(net, layer, data):\n",
    "    net.eval()\n",
    "    getattr(net, layer).register_forward_hook(get_activation('__net__'))\n",
    "    output = net(data).detach()\n",
    "    act = activation.pop('__net__').squeeze()\n",
    "    show_activation(act, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold   1 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.667    |    SimpleNet      0.703    ||    BoundNet       0.982    |    SimpleNet      0.982\n",
      "\t              High           0.483    |    Low            0.679    ||    High           0.804    |    Low            0.665\n",
      "\tCoverage      High           0.368    |    Low            0.000    ||    High           0.673    |    Low            0.000\n",
      "Fold   2 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.649    |    SimpleNet      0.529    ||    BoundNet       0.979    |    SimpleNet      0.979\n",
      "\t              High           0.516    |    Low            0.679    ||    High           0.904    |    Low            0.665\n",
      "\tCoverage      High           0.421    |    Low            0.000    ||    High           0.824    |    Low            0.000\n",
      "Fold   3 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.732    |    SimpleNet      0.718    ||    BoundNet       0.985    |    SimpleNet      0.985\n",
      "\t              High           0.516    |    Low            0.667    ||    High           0.759    |    Low            0.665\n",
      "\tCoverage      High           0.421    |    Low            0.056    ||    High           0.612    |    Low            0.000\n",
      "Fold   4 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.800    |    SimpleNet      0.750    ||    BoundNet       0.975    |    SimpleNet      0.976\n",
      "\t              High           0.581    |    Low            0.679    ||    High           0.769    |    Low            0.665\n",
      "\tCoverage      High           0.474    |    Low            0.000    ||    High           0.624    |    Low            0.000\n",
      "Fold   5 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.595    |    SimpleNet      0.564    ||    BoundNet       0.979    |    SimpleNet      0.979\n",
      "\t              High           0.533    |    Low            0.655    ||    High           0.810    |    Low            0.668\n",
      "\tCoverage      High           0.444    |    Low            0.000    ||    High           0.681    |    Low            0.000\n",
      "Fold   6 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.727    |    SimpleNet      0.744    ||    BoundNet       0.978    |    SimpleNet      0.978\n",
      "\t              High           0.621    |    Low            0.655    ||    High           0.839    |    Low            0.668\n",
      "\tCoverage      High           0.500    |    Low            0.000    ||    High           0.723    |    Low            0.000\n",
      "Fold   7 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.789    |    SimpleNet      0.737    ||    BoundNet       0.979    |    SimpleNet      0.979\n",
      "\t              High           0.645    |    Low            0.655    ||    High           0.843    |    Low            0.668\n",
      "\tCoverage      High           0.556    |    Low            0.000    ||    High           0.729    |    Low            0.000\n",
      "Fold   8 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.667    |    SimpleNet      0.649    ||    BoundNet       0.975    |    SimpleNet      0.976\n",
      "\t              High           0.533    |    Low            0.655    ||    High           0.839    |    Low            0.668\n",
      "\tCoverage      High           0.444    |    Low            0.000    ||    High           0.723    |    Low            0.000\n",
      "Fold   9 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.683    |    SimpleNet      0.611    ||    BoundNet       0.975    |    SimpleNet      0.976\n",
      "\t              High           0.444    |    Low            0.667    ||    High           0.823    |    Low            0.668\n",
      "\tCoverage      High           0.333    |    Low            0.000    ||    High           0.699    |    Low            0.006\n",
      "Fold  10 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.600    |    SimpleNet      0.615    ||    BoundNet       0.985    |    SimpleNet      0.985\n",
      "\t              High           0.500    |    Low            0.667    ||    High           0.855    |    Low            0.667\n",
      "\tCoverage      High           0.389    |    Low            0.000    ||    High           0.747    |    Low            0.000\n"
     ]
    }
   ],
   "source": [
    "skf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=104)\n",
    "bnet_split_res = cross_valid(x_data, y_data, train_boundnet, skf)\n",
    "snet_split_res = cross_valid(x_data, y_data, train_simplenet, skf)\n",
    "\n",
    "for i, ((bt, tt, bv, tv), (st, _, sv, _)) in enumerate(zip(bnet_split_res, snet_split_res)):\n",
    "    prompts = []\n",
    "    for b, s, t in [[bt, st, tt],[bv, sv, tv]]:\n",
    "        b_f1_score = metrics.f1_score(t, b, average=\"binary\")\n",
    "        s_f1_score = metrics.f1_score(t, s, average=\"binary\")\n",
    "        prompts.append(f\"{'BoundNet':<15}{b_f1_score:.3f}{'|':^9}{'SimpleNet':<15}{s_f1_score:.3f}\")\n",
    "\n",
    "        hi_f1_score = metrics.f1_score(t, b.hi, average=\"binary\")\n",
    "        lo_f1_score = metrics.f1_score(t, b.lo, average=\"binary\")\n",
    "        prompts.append(f\"{'High':<15}{hi_f1_score:.3f}{'|':^9}{'Low':<15}{lo_f1_score:.3f}\")\n",
    "\n",
    "        hi_cov_score = cov_score(t, b.hi)[1]\n",
    "        lo_cov_score = cov_score(t, b.lo)[0]\n",
    "        prompts.append(f\"{'High':<15}{hi_cov_score:.3f}{'|':^9}{'Low':<15}{lo_cov_score:.3f}\")\n",
    "\n",
    "    sep_tv = f\"{'||':^10}\"\n",
    "    print(f\"Fold {i+1:3} :            {'Valid':^49}{sep_tv}{'Train':^49}\",\n",
    "          f\"\\tF1 score      {prompts[3]}{sep_tv}{prompts[0]}\",\n",
    "          f\"\\t              {prompts[4]}{sep_tv}{prompts[1]}\",\n",
    "          f\"\\tCoverage      {prompts[5]}{sep_tv}{prompts[2]}\",\n",
    "          sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
