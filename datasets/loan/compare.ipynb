{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict \n",
    "from sklearn import metrics, model_selection\n",
    "from torch.autograd import Function\n",
    "from torch.optim import Adam\n",
    "\n",
    "filepath = os.path.abspath('')\n",
    "sys.path.append(os.path.join(filepath, \"..\", \"..\", \"compiling_nn\"))\n",
    "from build_odd import compile_nn\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics, Activations, Loss and Networks definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(y_true, y_pred):\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix, display_labels=[False, True])\n",
    "    return cm_display\n",
    "\n",
    "def plot_cm(y_true, y_pred):\n",
    "    cm_display = cm(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4,8))\n",
    "    cm_display.plot(ax=ax, colorbar=False)\n",
    "\n",
    "def plot_combine_cm(cms, titles=None):\n",
    "    n = len(cms)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(4*n, 8))\n",
    "    if titles:\n",
    "        for ax, cm, title in zip(axs, cms, titles):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "            ax.set_title(title)\n",
    "    else:\n",
    "        for ax, cm in zip(axs, cms):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "    fig.tight_layout()\n",
    "\n",
    "def cov_score(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    scores = {}\n",
    "\n",
    "    for label in labels:\n",
    "        indices_true = np.where(y_true == label)[0]\n",
    "        indices_pred = np.where(y_pred == label)[0]\n",
    "        scores[label] = len(np.intersect1d(indices_true, indices_pred))/len(indices_true)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def cross_valid(X, Y, train_func, skf, **kw_train):\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        model, y_pred = train_func(x_train, y_train, **kw_train)\n",
    "        model.eval()\n",
    "        yield y_pred.detach().round(), y_train, model(x_test).detach(), y_test\n",
    "\n",
    "def tnot(a): return torch.logical_not(a)\n",
    "def tor(a,b): return torch.logical_or(a,b)\n",
    "def tand(a,b): return torch.logical_and(a,b)\n",
    "def txor(a,b): return torch.logical_xor(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        output = torch.where(input>=0, torch.tensor(1.0), torch.tensor(0.0))\n",
    "        ctx.save_for_backward(input)\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = torch.zeros_like(input)\n",
    "        return grad_input\n",
    "    \n",
    "class StepActivation(nn.Module):\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            return torch.sigmoid(input)\n",
    "        else:\n",
    "            return StepFunction.apply(input)\n",
    "    \n",
    "class AsymMSELoss(nn.Module): # https://www.desmos.com/calculator/zmxcluqhkt\n",
    "    def __init__(self, p=2):\n",
    "        super(AsymMSELoss, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        dif = label - input\n",
    "        a = torch.square(dif)\n",
    "        b = a*self.p\n",
    "        loss = torch.where(dif < 0, b, a)\n",
    "        loss = torch.mean(loss)\n",
    "        return loss\n",
    "    \n",
    "class AsymBCELoss(nn.Module):\n",
    "    def __init__(self, p=2):\n",
    "        super(AsymBCELoss, self).__init__()\n",
    "        assert(p>0)\n",
    "        self.p1 = p if p >= 1 else 1\n",
    "        self.p2 = 1/p if p < 1 else 1\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        loss1 = torch.log(1-input+1e-8)\n",
    "        loss1 = loss1.clamp(min=-100)\n",
    "        loss2 = torch.log(input+1e-8)\n",
    "        loss2 = loss2.clamp(min=-100)\n",
    "        loss = -(self.p1*(1-label)*loss1+self.p2*label*loss2)\n",
    "        \n",
    "        loss = torch.mean(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproxNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        hl1 = 10\n",
    "\n",
    "        self.nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(25,hl1)),\n",
    "            ('a1', StepActivation()),\n",
    "            ('l2', nn.Linear(hl1,1)),\n",
    "            ('a2', StepActivation())\n",
    "        ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CentralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self. nn = nn.Sequential(\n",
    "            nn.Linear(25,hl1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl1,hl2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl2,1),\n",
    "            StepActivation(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class BoundNetResults():\n",
    "    def __init__(self, x, xhi, xnn, xlo):\n",
    "        self.x = x\n",
    "        self.hi = xhi\n",
    "        self.nn = xnn\n",
    "        self.lo = xlo\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if hasattr(self.x, name):\n",
    "            return getattr(self.x, name)\n",
    "        else:\n",
    "            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
    "    \n",
    "    def __dir__(self):\n",
    "        return dir(self.x)\n",
    "    \n",
    "    def detach(self):\n",
    "        self.x = self.x.detach()\n",
    "        self.hi = self.hi.detach()\n",
    "        self.nn = self.nn.detach()\n",
    "        self.lo = self.lo.detach()\n",
    "        return self\n",
    "    \n",
    "    def round(self, *args):\n",
    "        self.x = self.x.round(*args)\n",
    "        self.hi = self.hi.round(*args)\n",
    "        self.nn = self.nn.round(*args)\n",
    "        self.lo = self.lo.round(*args)\n",
    "        return self\n",
    "\n",
    "class BoundNetLoss():\n",
    "    def __init__(self, hi, nn, lo):\n",
    "        self.hi_loss_fn = hi\n",
    "        self.nn_loss_fn = nn\n",
    "        self.lo_loss_fn = lo\n",
    "\n",
    "    def __call__(self, pred, true):\n",
    "        self.nn_loss = self.nn_loss_fn(pred.nn, true)\n",
    "\n",
    "        target = pred.nn.detach()\n",
    "        self.hi_loss = self.hi_loss_fn(pred.hi, target)\n",
    "        self.lo_loss = self.lo_loss_fn(pred.lo, target)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def backward(self):\n",
    "        self.nn_loss.backward()\n",
    "        self.hi_loss.backward()\n",
    "        self.lo_loss.backward()\n",
    "\n",
    "class BoundNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # high approx nn (bigger = very long to compute into ODD)\n",
    "        self.hi = ApproxNet()\n",
    "\n",
    "        # low approx nn\n",
    "        self.lo = ApproxNet()\n",
    "\n",
    "        # nn to approximate (can make it bigger easily)\n",
    "        self.nn = CentralNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        xhi = self.hi(x)\n",
    "        xnn = self.nn(x)\n",
    "        xlo = self.lo(x)\n",
    "        x = torch.where(xhi>0.5, xhi, torch.where(xlo<0.5, xlo, xnn))\n",
    "        \n",
    "        x = BoundNetResults(x, xhi, xnn, xlo)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Linear(25,hl1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl1,hl2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hl2,1),\n",
    "            StepActivation(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"loan_data_set.csv\", sep=\",\")\n",
    "df = df.drop(columns=[\"Loan_ID\"])\n",
    "\n",
    "# Remove above 98.5th percentile for 'ApplicantIncome' and 'CoapplicantIncome'\n",
    "df_rank = df[[\"ApplicantIncome\", \"CoapplicantIncome\"]]\n",
    "df_rank[\"rankA\"] = df_rank[[\"ApplicantIncome\"]].rank(pct=True)\n",
    "df_rank[\"rankCo\"] = df_rank[\"CoapplicantIncome\"].rank(pct=True)\n",
    "\n",
    "df = df.loc[(df_rank[\"rankA\"]<=0.985) & (df_rank[\"rankCo\"]<=0.985)]\n",
    "df.index = range(len(df))\n",
    "\n",
    "# Transform using hot encoding\n",
    "df_y = pd.get_dummies(df[[\"Loan_Status\"]], drop_first=True)\n",
    "df_x = df.drop(columns=[\"Loan_Status\"])\n",
    "\n",
    "nunique = df_x.nunique(axis=0)\n",
    "df_x_mean = df_x.mean(axis=0, numeric_only=True)\n",
    "\n",
    "for col, n in nunique.items():\n",
    "    if n > 4:\n",
    "        df_x[col] = df_x[col].apply(lambda x : min(4, x//(.5*df_x_mean[col])))\n",
    "\n",
    "df_x = pd.get_dummies(df_x, columns=df_x.columns, drop_first=True)\n",
    "\n",
    "# Balance dataset\n",
    "itrue = df_y.index[df_y[\"Loan_Status_Y\"]==1].tolist()\n",
    "ifalse = df_y.index[df_y[\"Loan_Status_Y\"]==0].tolist()\n",
    "\n",
    "swap = len(itrue) > len(ifalse)\n",
    "if swap:\n",
    "    itrue,ifalse=ifalse,itrue\n",
    "\n",
    "ifalse = random.choices(ifalse, k=len(itrue))\n",
    "\n",
    "if swap:\n",
    "    itrue,ifalse=ifalse,itrue\n",
    "\n",
    "# print(df_y.iloc[itrue+ifalse].value_counts())\n",
    "\n",
    "x_data=torch.Tensor(df_x.iloc[itrue+ifalse].to_numpy(dtype=int))\n",
    "y_data=torch.Tensor(df_y.iloc[itrue+ifalse].to_numpy(dtype=int))\n",
    "\n",
    "# print(x_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, model, loss_fn, optimizer, max_epoch):\n",
    "    for _ in range(max_epoch):\n",
    "        model.train()\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # loss with true y values\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, y_pred\n",
    "\n",
    "def train_boundnet(x, y, max_epoch=5000, learning_rate=1e-2, weight_decay=1e-6):\n",
    "    model = BoundNet()\n",
    "    loss_fn = BoundNetLoss(AsymBCELoss(50), nn.BCELoss(), AsymBCELoss(.02))\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    return train_model(x, y, model, loss_fn, optimizer, max_epoch=max_epoch)\n",
    "\n",
    "def train_simplenet(x, y, max_epoch=5000, learning_rate=1e-2, weight_decay=1e-6):\n",
    "    model = SimpleNet()\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    return train_model(x, y, model, loss_fn, optimizer, max_epoch=max_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def show_activation(act, output):\n",
    "    # Mean activation per output\n",
    "    act_ones  = torch.where(output==1, act, torch.zeros(act.size()))\n",
    "    act_zeros = torch.where(output==0, act, torch.zeros(act.size()))\n",
    "\n",
    "    mean_ones  = torch.mean(act_ones, dim=0)\n",
    "    mean_zeros = torch.mean(act_zeros, dim=0)\n",
    "\n",
    "    # Figure initialization\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    tick_kw = {'left': False, 'bottom': False, 'labelleft': False}\n",
    "\n",
    "    # Normalize cmap accross both images\n",
    "    min_act = min(mean_ones.min().item(), mean_zeros.min().item())\n",
    "    max_act = max(mean_ones.max().item(), mean_zeros.max().item())\n",
    "\n",
    "    color_map = 'PRGn'\n",
    "\n",
    "    ax[0].imshow(mean_zeros.unsqueeze(0), cmap=color_map, vmin=min_act, vmax=max_act)\n",
    "    ax[0].tick_params(**tick_kw)\n",
    "    ax[0].set_title(\"activation moyenne de la couche cachée avec 0 en sortie\")\n",
    "\n",
    "    ax[1].imshow(mean_ones.unsqueeze(0), cmap=color_map, vmin=min_act, vmax=max_act)\n",
    "    ax[1].tick_params(**tick_kw)\n",
    "    ax[1].set_title(\"activation moyenne de la couche cachée avec 1 en sortie\")\n",
    "\n",
    "    # Show text on cells\n",
    "    for i, (v0, v1) in enumerate(zip(mean_zeros, mean_ones)):\n",
    "        ax[0].text(i, 0, f\"{v0.item():.2f}\", ha=\"center\", va=\"center\")\n",
    "        ax[1].text(i, 0, f\"{v1.item():.2f}\", ha=\"center\", va=\"center\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_activation(net, layer, data):\n",
    "    net.eval()\n",
    "    getattr(net, layer).register_forward_hook(get_activation('__net__'))\n",
    "    output = net(data).detach()\n",
    "    act = activation.pop('__net__').squeeze()\n",
    "    show_activation(act, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold   1 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.810    |    SimpleNet      0.789    ||    BoundNet       0.985    |    SimpleNet      0.985\n",
      "\t              High           0.778    |    Low            0.723    ||    High           0.929    |    Low            0.946\n",
      "\tCoverage      High           0.737    |    Low            0.895    ||    High           0.867    |    Low            1.000\n",
      "\t              High           0.833    |    Low            0.389    ||    High           1.000    |    Low            0.886\n",
      "Fold   2 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.737    |    SimpleNet      0.743    ||    BoundNet       0.985    |    SimpleNet      0.985\n",
      "\t              High           0.600    |    Low            0.698    ||    High           0.939    |    Low            0.889\n",
      "\tCoverage      High           0.474    |    Low            0.789    ||    High           0.885    |    Low            1.000\n",
      "\t              High           0.889    |    Low            0.500    ||    High           1.000    |    Low            0.753\n",
      "Fold   3 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.718    |    SimpleNet      0.684    ||    BoundNet       0.985    |    SimpleNet      0.985\n",
      "\t              High           0.703    |    Low            0.683    ||    High           0.935    |    Low            0.932\n",
      "\tCoverage      High           0.684    |    Low            0.737    ||    High           0.879    |    Low            1.000\n",
      "\t              High           0.722    |    Low            0.556    ||    High           1.000    |    Low            0.855\n",
      "Fold   4 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.703    |    SimpleNet      0.615    ||    BoundNet       0.985    |    SimpleNet      0.985\n",
      "\t              High           0.516    |    Low            0.718    ||    High           0.878    |    Low            0.914\n",
      "\tCoverage      High           0.421    |    Low            0.737    ||    High           0.782    |    Low            1.000\n",
      "\t              High           0.778    |    Low            0.667    ||    High           1.000    |    Low            0.813\n",
      "Fold   5 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.629    |    SimpleNet      0.632    ||    BoundNet       0.982    |    SimpleNet      0.982\n",
      "\t              High           0.296    |    Low            0.732    ||    High           0.863    |    Low            0.910\n",
      "\tCoverage      High           0.222    |    Low            0.833    ||    High           0.759    |    Low            1.000\n",
      "\t              High           0.737    |    Low            0.579    ||    High           1.000    |    Low            0.800\n",
      "Fold   6 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.595    |    SimpleNet      0.571    ||    BoundNet       0.988    |    SimpleNet      0.988\n",
      "\t              High           0.483    |    Low            0.667    ||    High           0.742    |    Low            0.853\n",
      "\tCoverage      High           0.389    |    Low            0.778    ||    High           0.590    |    Low            1.000\n",
      "\t              High           0.789    |    Low            0.474    ||    High           1.000    |    Low            0.655\n",
      "Fold   7 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.750    |    SimpleNet      0.778    ||    BoundNet       0.985    |    SimpleNet      0.985\n",
      "\t              High           0.686    |    Low            0.723    ||    High           0.893    |    Low            0.902\n",
      "\tCoverage      High           0.667    |    Low            0.944    ||    High           0.807    |    Low            1.000\n",
      "\t              High           0.737    |    Low            0.368    ||    High           1.000    |    Low            0.782\n",
      "Fold   8 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.788    |    SimpleNet      0.789    ||    BoundNet       0.982    |    SimpleNet      0.982\n",
      "\t              High           0.593    |    Low            0.769    ||    High           0.851    |    Low            0.922\n",
      "\tCoverage      High           0.444    |    Low            0.833    ||    High           0.741    |    Low            1.000\n",
      "\t              High           0.947    |    Low            0.684    ||    High           1.000    |    Low            0.830\n",
      "Fold   9 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.824    |    SimpleNet      0.769    ||    BoundNet       0.982    |    SimpleNet      0.982\n",
      "\t              High           0.643    |    Low            0.773    ||    High           0.851    |    Low            0.910\n",
      "\tCoverage      High           0.500    |    Low            0.944    ||    High           0.741    |    Low            1.000\n",
      "\t              High           0.944    |    Low            0.500    ||    High           1.000    |    Low            0.801\n",
      "Fold  10 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.611    |    SimpleNet      0.649    ||    BoundNet       0.985    |    SimpleNet      0.985\n",
      "\t              High           0.533    |    Low            0.619    ||    High           0.922    |    Low            0.927\n",
      "\tCoverage      High           0.444    |    Low            0.722    ||    High           0.855    |    Low            1.000\n",
      "\t              High           0.778    |    Low            0.389    ||    High           1.000    |    Low            0.843\n"
     ]
    }
   ],
   "source": [
    "skf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=104)\n",
    "bnet_split_res = cross_valid(x_data, y_data, train_boundnet, skf)\n",
    "snet_split_res = cross_valid(x_data, y_data, train_simplenet, skf)\n",
    "\n",
    "dict_metrics = {(modelname, metric, key): [] for modelname in (\"boundnet\", \"simplenet\", \"hinet\", \"lonet\") \n",
    "                for metric in (\"f1score\", \"coverage0\", \"coverage1\") for key in (\"valid\", \"train\")}\n",
    "\n",
    "for i, ((bt, tt, bv, tv), (st, _, sv, _)) in enumerate(zip(bnet_split_res, snet_split_res)):\n",
    "    prompts = []\n",
    "    sep_model = f\"{'|':^9}\"\n",
    "    for k, b, s, t in [[\"valid\", bv, sv, tv], [\"train\", bt, st, tt]]:\n",
    "        b_f1_score = metrics.f1_score(t, b, average=\"binary\")\n",
    "        s_f1_score = metrics.f1_score(t, s, average=\"binary\")\n",
    "        prompts.append(f\"{'BoundNet':<15}{b_f1_score:.3f}{sep_model}{'SimpleNet':<15}{s_f1_score:.3f}\")\n",
    "        dict_metrics[('boundnet', 'f1score', k)].append(b_f1_score)\n",
    "        dict_metrics[('simplenet', 'f1score', k)].append(s_f1_score)\n",
    "\n",
    "        hi_f1_score = metrics.f1_score(t, b.hi, average=\"binary\")\n",
    "        lo_f1_score = metrics.f1_score(t, b.lo, average=\"binary\")\n",
    "        prompts.append(f\"{'High':<15}{hi_f1_score:.3f}{sep_model}{'Low':<15}{lo_f1_score:.3f}\")\n",
    "        dict_metrics[('hinet', 'f1score', k)].append(hi_f1_score)\n",
    "        dict_metrics[('lonet', 'f1score', k)].append(lo_f1_score)\n",
    "\n",
    "        hi_cov_score = cov_score(t, b.hi)\n",
    "        lo_cov_score = cov_score(t, b.lo)\n",
    "        prompts.append(f\"{'High':<15}{hi_cov_score[1]:.3f}{sep_model}{'Low':<15}{lo_cov_score[1]:.3f}\")\n",
    "        prompts.append(f\"{'High':<15}{hi_cov_score[0]:.3f}{sep_model}{'Low':<15}{lo_cov_score[0]:.3f}\")\n",
    "        dict_metrics[('hinet', 'coverage1', k)].append(hi_cov_score[1])\n",
    "        dict_metrics[('lonet', 'coverage1', k)].append(lo_cov_score[1])\n",
    "        dict_metrics[('hinet', 'coverage0', k)].append(hi_cov_score[0])\n",
    "        dict_metrics[('lonet', 'coverage0', k)].append(lo_cov_score[0])\n",
    "\n",
    "    sep_tv = f\"{'||':^10}\"\n",
    "    print(f\"Fold {i+1:3} :            {'Valid':^49}{sep_tv}{'Train':^49}\",\n",
    "          f\"\\tF1 score      {prompts[0]}{sep_tv}{prompts[4]}\",\n",
    "          f\"\\t              {prompts[1]}{sep_tv}{prompts[5]}\",\n",
    "          f\"\\tCoverage      {prompts[2]}{sep_tv}{prompts[6]}\",\n",
    "          f\"\\t              {prompts[3]}{sep_tv}{prompts[7]}\",\n",
    "          sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average  :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      BoundNet       0.716    |    SimpleNet      0.702    ||    BoundNet       0.984    |    SimpleNet      0.984\n",
      "\t              High           0.583    |    Low            0.710    ||    High           0.880    |    Low            0.911\n",
      "\tCoverage      High           0.498    |    Low            0.821    ||    High           0.791    |    Low            1.000\n",
      "\t              High           0.815    |    Low            0.511    ||    High           1.000    |    Low            0.802\n"
     ]
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame.from_dict(dict_metrics, orient='index')\n",
    "mean_metrics = df_metrics.mean(axis=1)\n",
    "mean_prompts = [\n",
    "    f\"{'BoundNet':<15}{mean_metrics[('boundnet', 'f1score', 'valid')]:.3f}{sep_model}{'SimpleNet':<15}{mean_metrics[('simplenet', 'f1score', 'valid')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'f1score', 'valid')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'f1score', 'valid')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'coverage1', 'valid')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'coverage1', 'valid')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'coverage0', 'valid')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'coverage0', 'valid')]:.3f}\",\n",
    "    f\"{'BoundNet':<15}{mean_metrics[('boundnet', 'f1score', 'train')]:.3f}{sep_model}{'SimpleNet':<15}{mean_metrics[('simplenet', 'f1score', 'train')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'f1score', 'train')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'f1score', 'train')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'coverage1', 'train')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'coverage1', 'train')]:.3f}\",\n",
    "    f\"{'High':<15}{mean_metrics[('hinet', 'coverage0', 'train')]:.3f}{sep_model}{'Low':<15}{mean_metrics[('lonet', 'coverage0', 'train')]:.3f}\",\n",
    "]\n",
    "print(f\"Average  :            {'Valid':^49}{sep_tv}{'Train':^49}\",\n",
    "          f\"\\tF1 score      {mean_prompts[0]}{sep_tv}{mean_prompts[4]}\",\n",
    "          f\"\\t              {mean_prompts[1]}{sep_tv}{mean_prompts[5]}\",\n",
    "          f\"\\tCoverage      {mean_prompts[2]}{sep_tv}{mean_prompts[6]}\",\n",
    "          f\"\\t              {mean_prompts[3]}{sep_tv}{mean_prompts[7]}\",\n",
    "          sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
