{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict \n",
    "from sklearn import metrics, model_selection\n",
    "from torch.optim import Adam\n",
    "\n",
    "sys.path.append(os.path.abspath(''))\n",
    "\n",
    "import utils.more_torch_functions as mtf\n",
    "\n",
    "from compiling_nn.build_odd import compile_nn\n",
    "from datasets.loan import get_loan_dataset\n",
    "from utils.custom_activations import StepActivation, StepFunction\n",
    "from utils.modules import Parallel, MaxLayer\n",
    "from utils.custom_loss import AsymBCELoss\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.autograd.gradcheck\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([280, 14])\n"
     ]
    }
   ],
   "source": [
    "np_x, np_y = get_loan_dataset(balancing=True, discretizing=False, hot_encoding=True, rmv_pct=0.985)\n",
    "x_data, y_data = torch.Tensor(np_x), torch.Tensor(np_y)\n",
    "input_size = x_data.size(1)\n",
    "print(x_data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(y_true, y_pred):\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix, display_labels=[False, True])\n",
    "    return cm_display\n",
    "\n",
    "def plot_cm(y_true, y_pred):\n",
    "    cm_display = cm(y_true, y_pred)\n",
    "    _, ax = plt.subplots(1, 1, figsize=(4,8))\n",
    "    cm_display.plot(ax=ax, colorbar=False)\n",
    "\n",
    "def plot_combine_cm(cms, titles=None):\n",
    "    n = len(cms)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(4*n, 8))\n",
    "    if titles:\n",
    "        for ax, cm, title in zip(axs, cms, titles):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "            ax.set_title(title)\n",
    "    else:\n",
    "        for ax, cm in zip(axs, cms):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "    fig.tight_layout()\n",
    "\n",
    "def cov_score(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    scores = {}\n",
    "\n",
    "    for label in labels:\n",
    "        indices_true = np.where(y_true == label)[0]\n",
    "        indices_pred = np.where(y_pred == label)[0]\n",
    "        scores[label] = len(np.intersect1d(indices_true, indices_pred))/len(indices_true)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def train_model(x, y, model, loss_fn, optimizer, max_epoch):\n",
    "    for _ in range(max_epoch):\n",
    "        model.train()\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def cross_valid(X, Y, model, loss_fn, optimizer, skf, **kw_train):\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        mtf.reset_model(model)\n",
    "        y_pred = train_model(x_train, y_train, model, loss_fn, optimizer, **kw_train)\n",
    "        y_pred_train = y_pred.detach().round()\n",
    "        model.eval()\n",
    "        y_pred_eval = model(x_test).detach()\n",
    "        yield y_pred_train, y_train, y_pred_eval, y_test\n",
    "\n",
    "def tnot(a): return torch.logical_not(a)\n",
    "def tor(a,b): return torch.logical_or(a,b)\n",
    "def tand(a,b): return torch.logical_and(a,b)\n",
    "def txor(a,b): return torch.logical_xor(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproxNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        hl1 = 10\n",
    "\n",
    "        self.nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', StepActivation()),\n",
    "            ('l2', nn.Linear(hl1,1)),\n",
    "            ('a2', StepActivation())\n",
    "        ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CentralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self. nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', nn.Sigmoid()),\n",
    "            ('l2', nn.Linear(hl1,hl2)),\n",
    "            ('a2', nn.Sigmoid()),\n",
    "            ('l3', nn.Linear(hl2,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Network (and related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResults():\n",
    "    def __init__(self, *tensors):\n",
    "        for tensor in tensors:\n",
    "            self.register_result(tensor)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if hasattr(self.x, name):\n",
    "            return getattr(self.x, name)\n",
    "        else:\n",
    "            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
    "    \n",
    "    def __dir__(self):\n",
    "        return dir(self.x)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join([str(t) for t in self.tensors()])\n",
    "\n",
    "    def tensors(self):\n",
    "        for v in self.__dict__.values():\n",
    "            yield v\n",
    "\n",
    "    def detach(self):\n",
    "        for t in self.tensors():\n",
    "            t.detach()\n",
    "        return self\n",
    "    \n",
    "    def round(self, *args):\n",
    "        for t in self.tensors():\n",
    "            t.round(*args)\n",
    "        return self\n",
    "\n",
    "class Netv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.a1 = ApproxNet()\n",
    "        self.a2 = ApproxNet()\n",
    "        self.nn = CentralNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        xa1 = self.a1(x)\n",
    "        xa2 = self.a2(x)\n",
    "        xnn = self.nn(x)\n",
    "\n",
    "        res = [xnn, xa1, xa2]\n",
    "\n",
    "        # /!\\ to change for backward propagation /!\\\n",
    "        x = mtf.bitwise_big_or(*[(torch.round(t)).to(bool) for t in res])\n",
    "        # maximum ???\n",
    "        # xmax = mtf.maximum(res)\n",
    "        # x = torch.where(xmax > 0.5, xmax, xnn)\n",
    "\n",
    "        x = NetResults(x, *res)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Netv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('nets', Parallel(OrderedDict([\n",
    "                ('nn', CentralNet()),\n",
    "                ('approx1', ApproxNet()),\n",
    "                ('approx2', ApproxNet()),\n",
    "            ]))),\n",
    "            ('or', MaxLayer()),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "\n",
    "intermediate_outputs = {}\n",
    "def get_intermediate_outputs(name):\n",
    "    def hook(model, input, output):\n",
    "        if model.training:\n",
    "            intermediate_outputs.setdefault(name, dict())[\"train\"] = output\n",
    "        else:\n",
    "            intermediate_outputs.setdefault(name, dict())[\"valid\"] = output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold   1 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.688    |    CentralNet     0.690    ||    Net            1.000    |    CentralNet     0.996\n",
      "\t              Approx 1       0.381    |    Approx 2       0.421    ||    Approx 1       0.880    |    Approx 2       0.839\n",
      "\tCoverage      CentralNet     0.643    |    CentralNet     0.714    ||    CentralNet     1.000    |    CentralNet     0.992\n",
      "\t              Approx 1       0.786    |    Approx 1       0.286    ||    Approx 1       1.000    |    Approx 1       0.786\n",
      "\t              Approx 2       0.929    |    Approx 2       0.286    ||    Approx 2       1.000    |    Approx 2       0.722\n",
      "Fold   2 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.600    |    CentralNet     0.643    ||    Net            1.000    |    CentralNet     0.984\n",
      "\t              Approx 1       0.476    |    Approx 2       0.462    ||    Approx 1       0.822    |    Approx 2       0.904\n",
      "\tCoverage      CentralNet     0.643    |    CentralNet     0.643    ||    CentralNet     1.000    |    CentralNet     0.968\n",
      "\t              Approx 1       0.857    |    Approx 1       0.357    ||    Approx 1       1.000    |    Approx 1       0.698\n",
      "\t              Approx 2       0.571    |    Approx 2       0.429    ||    Approx 2       1.000    |    Approx 2       0.825\n",
      "Fold   3 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.813    |    CentralNet     0.759    ||    Net            1.000    |    CentralNet     0.988\n",
      "\t              Approx 1       0.640    |    Approx 2       0.500    ||    Approx 1       0.909    |    Approx 2       0.811\n",
      "\tCoverage      CentralNet     0.714    |    CentralNet     0.786    ||    CentralNet     1.000    |    CentralNet     0.976\n",
      "\t              Approx 1       0.786    |    Approx 1       0.571    ||    Approx 1       1.000    |    Approx 1       0.833\n",
      "\t              Approx 2       0.714    |    Approx 2       0.429    ||    Approx 2       1.000    |    Approx 2       0.683\n",
      "Fold   4 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.875    |    CentralNet     0.815    ||    Net            1.000    |    CentralNet     0.971\n",
      "\t              Approx 1       0.800    |    Approx 2       0.815    ||    Approx 1       0.828    |    Approx 2       0.885\n",
      "\tCoverage      CentralNet     0.857    |    CentralNet     0.786    ||    CentralNet     1.000    |    CentralNet     0.944\n",
      "\t              Approx 1       0.929    |    Approx 1       0.714    ||    Approx 1       1.000    |    Approx 1       0.706\n",
      "\t              Approx 2       0.857    |    Approx 2       0.786    ||    Approx 2       1.000    |    Approx 2       0.794\n",
      "Fold   5 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.750    |    CentralNet     0.696    ||    Net            0.996    |    CentralNet     0.885\n",
      "\t              Approx 1       0.741    |    Approx 2       0.593    ||    Approx 1       0.959    |    Approx 2       0.900\n",
      "\tCoverage      CentralNet     0.929    |    CentralNet     0.571    ||    CentralNet     1.000    |    CentralNet     0.794\n",
      "\t              Approx 1       0.786    |    Approx 1       0.714    ||    Approx 1       0.992    |    Approx 1       0.929\n",
      "\t              Approx 2       0.643    |    Approx 2       0.571    ||    Approx 2       1.000    |    Approx 2       0.817\n",
      "Fold   6 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.813    |    CentralNet     0.786    ||    Net            1.000    |    CentralNet     1.000\n",
      "\t              Approx 1       0.583    |    Approx 2       0.750    ||    Approx 1       0.909    |    Approx 2       0.904\n",
      "\tCoverage      CentralNet     0.786    |    CentralNet     0.786    ||    CentralNet     1.000    |    CentralNet     1.000\n",
      "\t              Approx 1       0.786    |    Approx 1       0.500    ||    Approx 1       1.000    |    Approx 1       0.833\n",
      "\t              Approx 2       0.929    |    Approx 2       0.643    ||    Approx 2       1.000    |    Approx 2       0.825\n",
      "Fold   7 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.839    |    CentralNet     0.615    ||    Net            1.000    |    CentralNet     0.976\n",
      "\t              Approx 1       0.640    |    Approx 2       0.815    ||    Approx 1       0.855    |    Approx 2       0.941\n",
      "\tCoverage      CentralNet     0.714    |    CentralNet     0.571    ||    CentralNet     1.000    |    CentralNet     0.952\n",
      "\t              Approx 1       0.786    |    Approx 1       0.571    ||    Approx 1       1.000    |    Approx 1       0.746\n",
      "\t              Approx 2       0.857    |    Approx 2       0.786    ||    Approx 2       1.000    |    Approx 2       0.889\n",
      "Fold   8 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.706    |    CentralNet     0.733    ||    Net            1.000    |    CentralNet     0.980\n",
      "\t              Approx 1       0.571    |    Approx 2       0.643    ||    Approx 1       0.811    |    Approx 2       0.783\n",
      "\tCoverage      CentralNet     0.643    |    CentralNet     0.786    ||    CentralNet     1.000    |    CentralNet     0.960\n",
      "\t              Approx 1       0.571    |    Approx 1       0.571    ||    Approx 1       1.000    |    Approx 1       0.683\n",
      "\t              Approx 2       0.643    |    Approx 2       0.643    ||    Approx 2       1.000    |    Approx 2       0.643\n",
      "Fold   9 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.727    |    CentralNet     0.571    ||    Net            1.000    |    CentralNet     0.937\n",
      "\t              Approx 1       0.560    |    Approx 2       0.621    ||    Approx 1       0.963    |    Approx 2       0.954\n",
      "\tCoverage      CentralNet     0.571    |    CentralNet     0.571    ||    CentralNet     1.000    |    CentralNet     0.881\n",
      "\t              Approx 1       0.714    |    Approx 1       0.500    ||    Approx 1       1.000    |    Approx 1       0.929\n",
      "\t              Approx 2       0.571    |    Approx 2       0.643    ||    Approx 2       1.000    |    Approx 2       0.913\n",
      "Fold  10 :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.765    |    CentralNet     0.667    ||    Net            1.000    |    CentralNet     0.849\n",
      "\t              Approx 1       0.828    |    Approx 2       0.710    ||    Approx 1       0.992    |    Approx 2       0.963\n",
      "\tCoverage      CentralNet     0.857    |    CentralNet     0.571    ||    CentralNet     1.000    |    CentralNet     0.738\n",
      "\t              Approx 1       0.786    |    Approx 1       0.857    ||    Approx 1       1.000    |    Approx 1       0.984\n",
      "\t              Approx 2       0.571    |    Approx 2       0.786    ||    Approx 2       1.000    |    Approx 2       0.929\n"
     ]
    }
   ],
   "source": [
    "model = Netv2()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "model.net.nets.register_forward_hook(get_intermediate_outputs(\"parallel_out\"))\n",
    "\n",
    "skf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=104)\n",
    "bnet_split_res = cross_valid(x_data, y_data, model, loss_fn, optimizer, skf, max_epoch=5000)\n",
    "\n",
    "dict_metrics = {(modelname, metric, key): [] for modelname in (\"net\", \"nn\", \"a1net\", \"a2net\")\n",
    "                for metric in (\"f1score\", \"coverage0\", \"coverage1\") for key in (\"valid\", \"train\")}\n",
    "\n",
    "for i, (train_pred, train_true, valid_pred, valid_true) in enumerate(bnet_split_res):\n",
    "    out_nns = intermediate_outputs[\"parallel_out\"]\n",
    "    for d in out_nns.values():\n",
    "        for k, v in d.items():\n",
    "            d[k] = v.detach().round()\n",
    "\n",
    "    prompts = []\n",
    "    pn = 5\n",
    "    sep_model = f\"{'|':^9}\"\n",
    "    for k, pred, true in [[\"valid\", valid_pred, valid_true], [\"train\", train_pred, train_true]]:\n",
    "        net_f1_score = metrics.f1_score(true, pred, average=\"binary\")\n",
    "        nn_f1_score = metrics.f1_score(true, out_nns[k][\"nn\"], average=\"binary\")\n",
    "        prompts.append(f\"{'Net':<15}{net_f1_score:.3f}{sep_model}{'CentralNet':<15}{nn_f1_score:.3f}\")\n",
    "        dict_metrics[('net', 'f1score', k)].append(net_f1_score)\n",
    "        dict_metrics[('nn', 'f1score', k)].append(nn_f1_score)\n",
    "\n",
    "        a1_f1_score = metrics.f1_score(true, out_nns[k][\"approx1\"], average=\"binary\")\n",
    "        a2_f1_score = metrics.f1_score(true, out_nns[k][\"approx2\"], average=\"binary\")\n",
    "        prompts.append(f\"{'Approx 1':<15}{a1_f1_score:.3f}{sep_model}{'Approx 2':<15}{a2_f1_score:.3f}\")\n",
    "        dict_metrics[('a1net', 'f1score', k)].append(a1_f1_score)\n",
    "        dict_metrics[('a2net', 'f1score', k)].append(a2_f1_score)\n",
    "\n",
    "        nn_cov_score = cov_score(true, out_nns[k][\"nn\"])\n",
    "        a1_cov_score = cov_score(true, out_nns[k][\"approx1\"])\n",
    "        a2_cov_score = cov_score(true, out_nns[k][\"approx2\"])\n",
    "        prompts.append(f\"{'CentralNet':<15}{nn_cov_score[0]:.3f}{sep_model}{'CentralNet':<15}{nn_cov_score[1]:.3f}\")\n",
    "        prompts.append(f\"{'Approx 1':<15}{a1_cov_score[0]:.3f}{sep_model}{'Approx 1':<15}{a1_cov_score[1]:.3f}\")\n",
    "        prompts.append(f\"{'Approx 2':<15}{a2_cov_score[0]:.3f}{sep_model}{'Approx 2':<15}{a2_cov_score[1]:.3f}\")\n",
    "        dict_metrics[('nn', 'coverage1', k)].append(nn_cov_score[1])\n",
    "        dict_metrics[('a1net', 'coverage1', k)].append(a1_cov_score[1])\n",
    "        dict_metrics[('a2net', 'coverage1', k)].append(a2_cov_score[1])\n",
    "        dict_metrics[('nn', 'coverage0', k)].append(nn_cov_score[0])\n",
    "        dict_metrics[('a1net', 'coverage0', k)].append(a1_cov_score[0])\n",
    "        dict_metrics[('a2net', 'coverage0', k)].append(a2_cov_score[0])\n",
    "\n",
    "    sep_tv = f\"{'||':^10}\"\n",
    "    print(f\"Fold {i+1:3} :            {'Valid':^49}{sep_tv}{'Train':^49}\",\n",
    "          f\"\\tF1 score      {prompts[0]}{sep_tv}{prompts[pn+0]}\",\n",
    "          f\"\\t              {prompts[1]}{sep_tv}{prompts[pn+1]}\",\n",
    "          f\"\\tCoverage      {prompts[2]}{sep_tv}{prompts[pn+2]}\",\n",
    "          f\"\\t              {prompts[3]}{sep_tv}{prompts[pn+3]}\",\n",
    "          f\"\\t              {prompts[4]}{sep_tv}{prompts[pn+4]}\",\n",
    "          sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average  :                                  Valid                          ||                          Train                      \n",
      "\tF1 score      Net            0.757    |    CentralNet     0.697    ||    Net            1.000    |    CentralNet     0.957\n",
      "\t              Approx 1       0.622    |    Approx 2       0.633    ||    Approx 1       0.893    |    Approx 2       0.888\n",
      "\tCoverage      CentralNet     0.736    |    CentralNet     0.679    ||    CentralNet     1.000    |    CentralNet     0.921\n",
      "\t              Approx 1       0.779    |    Approx 1       0.564    ||    Approx 1       0.999    |    Approx 1       0.813\n",
      "\t              Approx 2       0.729    |    Approx 2       0.600    ||    Approx 2       1.000    |    Approx 2       0.804\n"
     ]
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame.from_dict(dict_metrics, orient='index')\n",
    "mean_metrics = df_metrics.mean(axis=1)\n",
    "mean_prompts = [\n",
    "    f\"{'Net':<15}{mean_metrics[('net', 'f1score', 'valid')]:.3f}{sep_model}{'CentralNet':<15}{mean_metrics[('nn', 'f1score', 'valid')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'f1score', 'valid')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'f1score', 'valid')]:.3f}\",\n",
    "    f\"{'CentralNet':<15}{mean_metrics[('nn', 'coverage0', 'valid')]:.3f}{sep_model}{'CentralNet':<15}{mean_metrics[('nn', 'coverage1', 'valid')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'coverage0', 'valid')]:.3f}{sep_model}{'Approx 1':<15}{mean_metrics[('a1net', 'coverage1', 'valid')]:.3f}\",\n",
    "    f\"{'Approx 2':<15}{mean_metrics[('a2net', 'coverage0', 'valid')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'coverage1', 'valid')]:.3f}\",\n",
    "    f\"{'Net':<15}{mean_metrics[('net', 'f1score', 'train')]:.3f}{sep_model}{'CentralNet':<15}{mean_metrics[('nn', 'f1score', 'train')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'f1score', 'train')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'f1score', 'train')]:.3f}\",\n",
    "    f\"{'CentralNet':<15}{mean_metrics[('nn', 'coverage0', 'train')]:.3f}{sep_model}{'CentralNet':<15}{mean_metrics[('nn', 'coverage1', 'train')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'coverage0', 'train')]:.3f}{sep_model}{'Approx 1':<15}{mean_metrics[('a1net', 'coverage1', 'train')]:.3f}\",\n",
    "    f\"{'Approx 2':<15}{mean_metrics[('a2net', 'coverage0', 'train')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'coverage1', 'train')]:.3f}\",\n",
    "]\n",
    "print(f\"Average  :            {'Valid':^49}{sep_tv}{'Train':^49}\",\n",
    "          f\"\\tF1 score      {mean_prompts[0]}{sep_tv}{mean_prompts[pn+0]}\",\n",
    "          f\"\\t              {mean_prompts[1]}{sep_tv}{mean_prompts[pn+1]}\",\n",
    "          f\"\\tCoverage      {mean_prompts[2]}{sep_tv}{mean_prompts[pn+2]}\",\n",
    "          f\"\\t              {mean_prompts[3]}{sep_tv}{mean_prompts[pn+3]}\",\n",
    "          f\"\\t              {mean_prompts[4]}{sep_tv}{mean_prompts[pn+4]}\",\n",
    "          sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
