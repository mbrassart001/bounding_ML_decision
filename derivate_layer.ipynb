{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict \n",
    "from sklearn import metrics, model_selection\n",
    "from torch.optim import Adam\n",
    "\n",
    "sys.path.append(os.path.abspath(''))\n",
    "\n",
    "import utils.more_torch_func as mtf\n",
    "\n",
    "from compiling_nn.build_odd import compile_nn\n",
    "from datasets.loan import get_loan_dataset\n",
    "from utils.custom_activations import StepActivation\n",
    "from utils.custom_loss import AsymBCELoss\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([280, 14])\n"
     ]
    }
   ],
   "source": [
    "np_x, np_y = get_loan_dataset(balancing=True, discretizing=False, hot_encoding=True, rmv_pct=0.985)\n",
    "x_data, y_data = torch.Tensor(np_x), torch.Tensor(np_y)\n",
    "input_size = x_data.size(1)\n",
    "print(x_data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(y_true, y_pred):\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix, display_labels=[False, True])\n",
    "    return cm_display\n",
    "\n",
    "def plot_cm(y_true, y_pred):\n",
    "    cm_display = cm(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4,8))\n",
    "    cm_display.plot(ax=ax, colorbar=False)\n",
    "\n",
    "def plot_combine_cm(cms, titles=None):\n",
    "    n = len(cms)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(4*n, 8))\n",
    "    if titles:\n",
    "        for ax, cm, title in zip(axs, cms, titles):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "            ax.set_title(title)\n",
    "    else:\n",
    "        for ax, cm in zip(axs, cms):\n",
    "            cm.plot(ax=ax, colorbar=False)\n",
    "    fig.tight_layout()\n",
    "\n",
    "def cov_score(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    scores = {}\n",
    "\n",
    "    for label in labels:\n",
    "        indices_true = np.where(y_true == label)[0]\n",
    "        indices_pred = np.where(y_pred == label)[0]\n",
    "        scores[label] = len(np.intersect1d(indices_true, indices_pred))/len(indices_true)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def cross_valid(X, Y, train_func, skf, **kw_train):\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        model, y_pred = train_func(x_train, y_train, **kw_train)\n",
    "        model.eval()\n",
    "        yield y_pred.detach().round(), y_train, model(x_test).detach(), y_test\n",
    "\n",
    "def tnot(a): return torch.logical_not(a)\n",
    "def tor(a,b): return torch.logical_or(a,b)\n",
    "def tand(a,b): return torch.logical_and(a,b)\n",
    "def txor(a,b): return torch.logical_xor(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproxNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        hl1 = 10\n",
    "\n",
    "        self.nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', StepActivation()),\n",
    "            ('l2', nn.Linear(hl1,1)),\n",
    "            ('a2', StepActivation())\n",
    "        ]))        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CentralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        hl1 = 50\n",
    "        hl2 = 25\n",
    "\n",
    "        self. nn = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(input_size,hl1)),\n",
    "            ('a1', nn.Sigmoid()),\n",
    "            ('l2', nn.Linear(hl1,hl2)),\n",
    "            ('a2', nn.Sigmoid()),\n",
    "            ('l3', nn.Linear(hl2,1)),\n",
    "            ('a3', StepActivation()),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.nn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class BoundNetResults():\n",
    "    def __init__(self, x, xnn, xapprox1, xapprox2):\n",
    "        self.x = x\n",
    "        self.nn = xnn\n",
    "        self.a1 = xapprox1\n",
    "        self.a2 = xapprox2\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if hasattr(self.x, name):\n",
    "            return getattr(self.x, name)\n",
    "        else:\n",
    "            raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
    "    \n",
    "    def __dir__(self):\n",
    "        return dir(self.x)\n",
    "    \n",
    "    def tensors(self):\n",
    "        for v in self.__dict__.values():\n",
    "            yield v\n",
    "\n",
    "    def detach(self):\n",
    "        for t in self.tensors():\n",
    "            t.detach()\n",
    "        return self\n",
    "    \n",
    "    def round(self, *args):\n",
    "        for t in self.tensors():\n",
    "            t.round(*args)\n",
    "        return self\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join([str(t) for t in self.tensors()])\n",
    "\n",
    "class BoundNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.a1 = ApproxNet()\n",
    "        self.a2 = ApproxNet()\n",
    "        self.nn = CentralNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        xa1 = self.a1(x)\n",
    "        xa2 = self.a2(x)\n",
    "        xnn = self.nn(x)\n",
    "\n",
    "        # /!\\ to change for backward propagation /!\\\n",
    "        # maximum ???\n",
    "        x = mtf.bitwise_big_or(*[torch.round(t).to(bool) for t in (xa1, xa2, xnn)])\n",
    "\n",
    "        x = BoundNetResults(x, xnn, xa1, xa2)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, model, loss_fn, optimizer, max_epoch):\n",
    "    for _ in range(max_epoch):\n",
    "        model.train()\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model, y_pred\n",
    "\n",
    "def train_boundnet(x, y, max_epoch=5000, learning_rate=1e-2, weight_decay=1e-6):\n",
    "    model = BoundNet()\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    return train_model(x, y, model, loss_fn, optimizer, max_epoch=max_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def show_activation(act, output):\n",
    "    # Mean activation per output\n",
    "    act_ones  = torch.where(output==1, act, torch.zeros(act.size()))\n",
    "    act_zeros = torch.where(output==0, act, torch.zeros(act.size()))\n",
    "\n",
    "    mean_ones  = torch.mean(act_ones, dim=0)\n",
    "    mean_zeros = torch.mean(act_zeros, dim=0)\n",
    "\n",
    "    # Figure initialization\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    tick_kw = {'left': False, 'bottom': False, 'labelleft': False}\n",
    "\n",
    "    # Normalize cmap accross both images\n",
    "    min_act = min(mean_ones.min().item(), mean_zeros.min().item())\n",
    "    max_act = max(mean_ones.max().item(), mean_zeros.max().item())\n",
    "\n",
    "    color_map = 'PRGn'\n",
    "\n",
    "    ax[0].imshow(mean_zeros.unsqueeze(0), cmap=color_map, vmin=min_act, vmax=max_act)\n",
    "    ax[0].tick_params(**tick_kw)\n",
    "    ax[0].set_title(\"activation moyenne de la couche cachée avec 0 en sortie\")\n",
    "\n",
    "    ax[1].imshow(mean_ones.unsqueeze(0), cmap=color_map, vmin=min_act, vmax=max_act)\n",
    "    ax[1].tick_params(**tick_kw)\n",
    "    ax[1].set_title(\"activation moyenne de la couche cachée avec 1 en sortie\")\n",
    "\n",
    "    # Show text on cells\n",
    "    for i, (v0, v1) in enumerate(zip(mean_zeros, mean_ones)):\n",
    "        ax[0].text(i, 0, f\"{v0.item():.2f}\", ha=\"center\", va=\"center\")\n",
    "        ax[1].text(i, 0, f\"{v1.item():.2f}\", ha=\"center\", va=\"center\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_activation(net, layer, data):\n",
    "    net.eval()\n",
    "    getattr(net, layer).register_forward_hook(get_activation('__net__'))\n",
    "    output = net(data).detach()\n",
    "    act = activation.pop('__net__').squeeze()\n",
    "    show_activation(act, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "binary_cross_entropy(): argument 'input' (position 1) must be Tensor, not BoundNetResults",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m bnet_split_res \u001b[38;5;241m=\u001b[39m cross_valid(x_data, y_data, train_boundnet, skf)\n\u001b[1;32m      4\u001b[0m dict_metrics \u001b[38;5;241m=\u001b[39m {(modelname, metric, key): [] \u001b[38;5;28;01mfor\u001b[39;00m modelname \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboundnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplenet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhinet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlonet\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m      5\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoverage0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoverage1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (bt, tt, bv, tv) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(bnet_split_res):\n\u001b[1;32m      8\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m     sep_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m^9\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m, in \u001b[0;36mcross_valid\u001b[0;34m(X, Y, train_func, skf, **kw_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m x_train, x_test \u001b[38;5;241m=\u001b[39m X[train_index], X[test_index]\n\u001b[1;32m     37\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m Y[train_index], Y[test_index]\n\u001b[0;32m---> 39\u001b[0m model, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mround(), y_train, model(x_test)\u001b[38;5;241m.\u001b[39mdetach(), y_test\n",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m, in \u001b[0;36mtrain_boundnet\u001b[0;34m(x, y, max_epoch, learning_rate, weight_decay)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[1;32m     17\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(x, y, model, loss_fn, optimizer, max_epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m----> 6\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/odd/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/odd/lib/python3.10/site-packages/torch/nn/modules/loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/odd/lib/python3.10/site-packages/torch/nn/functional.py:3071\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3037\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Function that measures the Binary Cross Entropy between the target and input\u001b[39;00m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;124;03mprobabilities.\u001b[39;00m\n\u001b[1;32m   3039\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m    >>> loss.backward()\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight):\n\u001b[0;32m-> 3071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3073\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3074\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3076\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3077\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_average\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3078\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3079\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3082\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_enum(size_average, reduce)\n",
      "File \u001b[0;32m~/miniconda3/envs/odd/lib/python3.10/site-packages/torch/overrides.py:1534\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1530\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[0;32m-> 1534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/odd/lib/python3.10/site-packages/torch/_tensor.py:1279\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunction():\n\u001b[0;32m-> 1279\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/odd/lib/python3.10/site-packages/torch/nn/functional.py:3095\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3092\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3093\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: binary_cross_entropy(): argument 'input' (position 1) must be Tensor, not BoundNetResults"
     ]
    }
   ],
   "source": [
    "skf = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=104)\n",
    "bnet_split_res = cross_valid(x_data, y_data, train_boundnet, skf)\n",
    "\n",
    "dict_metrics = {(modelname, metric, key): [] for modelname in (\"boundnet\", \"simplenet\", \"hinet\", \"lonet\") \n",
    "                for metric in (\"f1score\", \"coverage0\", \"coverage1\") for key in (\"valid\", \"train\")}\n",
    "\n",
    "for i, (bt, tt, bv, tv) in enumerate(bnet_split_res):\n",
    "    prompts = []\n",
    "    sep_model = f\"{'|':^9}\"\n",
    "    for k, b, t in [[\"valid\", bv, tv], [\"train\", bt, tt]]:\n",
    "        b_f1_score = metrics.f1_score(t, b, average=\"binary\")\n",
    "        s_f1_score = 0 # TODO\n",
    "        prompts.append(f\"{'BoundNet':<15}{b_f1_score:.3f}{sep_model}{'SimpleNet':<15}{s_f1_score:.3f}\")\n",
    "        dict_metrics[('boundnet', 'f1score', k)].append(b_f1_score)\n",
    "        dict_metrics[('simplenet', 'f1score', k)].append(s_f1_score)\n",
    "\n",
    "        a1_f1_score = metrics.f1_score(t, b.a1, average=\"binary\")\n",
    "        a2_f1_score = metrics.f1_score(t, b.a2, average=\"binary\")\n",
    "        prompts.append(f\"{'Approx 1':<15}{a1_f1_score:.3f}{sep_model}{'Approx 2':<15}{a2_f1_score:.3f}\")\n",
    "        dict_metrics[('a1net', 'f1score', k)].append(a1_f1_score)\n",
    "        dict_metrics[('a2net', 'f1score', k)].append(a2_f1_score)\n",
    "\n",
    "        a1_cov_score = cov_score(t, b.a1)\n",
    "        a2_cov_score = cov_score(t, b.a2)\n",
    "        prompts.append(f\"{'Approx 1':<15}{a1_cov_score[1]:.3f}{sep_model}{'Approx 2':<15}{a2_cov_score[1]:.3f}\")\n",
    "        prompts.append(f\"{'Approx 1':<15}{a1_cov_score[0]:.3f}{sep_model}{'Approx 2':<15}{a2_cov_score[0]:.3f}\")\n",
    "        dict_metrics[('a1net', 'coverage1', k)].append(a1_cov_score[1])\n",
    "        dict_metrics[('a2net', 'coverage1', k)].append(a2_cov_score[1])\n",
    "        dict_metrics[('a1net', 'coverage0', k)].append(a1_cov_score[0])\n",
    "        dict_metrics[('a2net', 'coverage0', k)].append(a2_cov_score[0])\n",
    "\n",
    "    sep_tv = f\"{'||':^10}\"\n",
    "    print(f\"Fold {i+1:3} :            {'Valid':^49}{sep_tv}{'Train':^49}\",\n",
    "          f\"\\tF1 score      {prompts[0]}{sep_tv}{prompts[4]}\",\n",
    "          f\"\\t              {prompts[1]}{sep_tv}{prompts[5]}\",\n",
    "          f\"\\tCoverage      {prompts[2]}{sep_tv}{prompts[6]}\",\n",
    "          f\"\\t              {prompts[3]}{sep_tv}{prompts[7]}\",\n",
    "          sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame.from_dict(dict_metrics, orient='index')\n",
    "mean_metrics = df_metrics.mean(axis=1)\n",
    "mean_prompts = [\n",
    "    f\"{'BoundNet':<15}{mean_metrics[('boundnet', 'f1score', 'valid')]:.3f}{sep_model}{'SimpleNet':<15}{mean_metrics[('simplenet', 'f1score', 'valid')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'f1score', 'valid')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'f1score', 'valid')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'coverage1', 'valid')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'coverage1', 'valid')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'coverage0', 'valid')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'coverage0', 'valid')]:.3f}\",\n",
    "    f\"{'BoundNet':<15}{mean_metrics[('boundnet', 'f1score', 'train')]:.3f}{sep_model}{'SimpleNet':<15}{mean_metrics[('simplenet', 'f1score', 'train')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'f1score', 'train')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'f1score', 'train')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'coverage1', 'train')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'coverage1', 'train')]:.3f}\",\n",
    "    f\"{'Approx 1':<15}{mean_metrics[('a1net', 'coverage0', 'train')]:.3f}{sep_model}{'Approx 2':<15}{mean_metrics[('a2net', 'coverage0', 'train')]:.3f}\",\n",
    "]\n",
    "print(f\"Average  :            {'Valid':^49}{sep_tv}{'Train':^49}\",\n",
    "          f\"\\tF1 score      {mean_prompts[0]}{sep_tv}{mean_prompts[4]}\",\n",
    "          f\"\\t              {mean_prompts[1]}{sep_tv}{mean_prompts[5]}\",\n",
    "          f\"\\tCoverage      {mean_prompts[2]}{sep_tv}{mean_prompts[6]}\",\n",
    "          f\"\\t              {mean_prompts[3]}{sep_tv}{mean_prompts[7]}\",\n",
    "          sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
